import yfinance as yf
import pandas as pd
import numpy as np
import requests
import time
import random
import os
import sys
from datetime import datetime
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# --- è¨­å®šã‚¨ãƒªã‚¢ ---
SEC_USER_AGENT = 'Minervini-Bot/Git-Full-v3 (contact: gozihiro17@gmail.com)'
LOCAL_SAVE_PATH = 'minervini_final_results.csv'
BATCH_SIZE = 50
BATCH_SLEEP_BASE = 85

def log(msg):
    print(msg, flush=True)

def upload_to_drive(file_path, drive_file_name):
    """OAuth 2.0ã‚’ä½¿ç”¨ã—ã¦Google Driveã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    client_id = os.environ.get('CLIENT_ID')
    client_secret = os.environ.get('CLIENT_SECRET')
    refresh_token = os.environ.get('REFRESH_TOKEN')
    folder_id = os.environ.get('GDRIVE_FOLDER_ID')

    if not all([client_id, client_secret, refresh_token, folder_id]):
        log("ã€è­¦å‘Šã€‘Driveè¨­å®šç”¨ã®ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return

    try:
        creds = Credentials(
            token=None, refresh_token=refresh_token, client_id=client_id,
            client_secret=client_secret, token_uri="https://oauth2.googleapis.com/token"
        )
        service = build('drive', 'v3', credentials=creds)
        file_metadata = {'name': drive_file_name, 'parents': [folder_id]}
        media = MediaFileUpload(file_path, mimetype='text/csv', resumable=True)
        service.files().create(body=file_metadata, media_body=media, fields='id').execute()
        log(f">> âœ… Driveã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {drive_file_name}")
    except Exception as e:
        log(f">> âŒ Driveã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")

def calculate_launchpad_score(df, ticker, tags, index_change):
    """
    ãƒŸãƒãƒ«ãƒ´ã‚£ãƒ‹/ã‚¨ãƒ«ãƒ€ãƒ¼æµã€ç™ºå°„å°ã‚¹ã‚³ã‚¢ã€ç®—å‡º (0-10ç‚¹)
    """
    if len(df) < 20: return 0
    
    # ç›´è¿‘ãƒ‡ãƒ¼ã‚¿
    c_today = df['Close'].iloc[-1]
    o_today = df['Open'].iloc[-1]
    h_today = df['High'].iloc[-1]
    l_today = df['Low'].iloc[-1]
    v_today = df['Volume'].iloc[-1]
    
    day_range = h_today - l_today
    if day_range == 0: return 0

    # ã€é‡è¦è¿½åŠ æ¡ä»¶ã€‘é™½ç·šåˆ¤å®šï¼šçµ‚å€¤ãŒå§‹å€¤ä»¥ä¸‹ï¼ˆé™°ç·šã¾ãŸã¯åŒå€¤ï¼‰ãªã‚‰ã€å³åº§ã«0ç‚¹ã¨ã—ã¦é™¤å¤–
    if c_today <= o_today:
        return 0
    
    # --- A. å…±é€šåŸºç¤ç‚¹ (æœ€å¤§6ç‚¹) ---
    base_score = 0
    # 1. Closing Range (é«˜å€¤å¼•ã‘)
    closing_range = (c_today - l_today) / day_range
    if closing_range >= 0.8: base_score += 2
    
    # 2. Narrow Range (å€¤å¹…åç¸®)
    avg_range_20 = (df['High'] - df['Low']).rolling(20).mean().iloc[-1]
    if day_range < (avg_range_20 * 0.8): base_score += 2
    
    # 3. No Upper Shadow (ä¸Šãƒ’ã‚²æ’é™¤)
    upper_shadow = h_today - max(o_today, c_today)
    if upper_shadow < (day_shadow_val := day_range * 0.1): base_score += 2

    # --- B. ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ãƒœãƒ¼ãƒŠã‚¹ (æœ€å¤§4ç‚¹) ---
    bonus_vcp = 0
    if "VCP_3Steps_Validated" in tags:
        # VDU (Volume Dry-up)
        vol_sma50 = df['Volume'].rolling(50).mean().iloc[-1]
        if v_today < (vol_sma50 * 0.5): bonus_vcp += 2
        # Closing Tightness (çµ‚å€¤ã®æ¨ªä¸¦ã³)
        last_3_closes = df['Close'].tail(3)
        if last_3_closes.std() < (c_today * 0.005): bonus_vcp += 2

    bonus_hb = 0
    if any("High-Base" in t for t in tags):
        # MA Support (20æ—¥ç·šä»˜è¿‘)
        sma20 = df['Close'].rolling(20).mean().iloc[-1]
        if l_today <= (sma20 * 1.015): bonus_hb += 2
        # Shakeout (ä¸‹ãƒ’ã‚²æŒ¯ã‚‹ã„è½ã¨ã—)
        lower_shadow = min(o_today, c_today) - l_today
        body_size = abs(c_today - o_today)
        if lower_shadow > body_size: bonus_hb += 2

    bonus_pp = 0
    if "PowerPlay(70%+)" in tags:
        # Momentum Persistence (é«˜å€¤åœç¶­æŒ)
        high_5d = df['High'].tail(5).max()
        if c_today >= (high_5d * 0.98): bonus_pp += 2
        # Relative Strength (é€†è¡Œé«˜)
        stock_change = (c_today / df['Close'].iloc[-2]) - 1
        if stock_change >= 0 and index_change < 0: bonus_pp += 2

    final_score = base_score + max(bonus_vcp, bonus_hb, bonus_pp)
    return min(10, final_score)

def get_market_health_summary():
    """æŒ‡æ•°ãƒ‡ãƒ¼ã‚¿è§£æã«ã‚ˆã‚‹å¸‚å ´ç’°å¢ƒåˆ¤å®š"""
    log(">> ã‚¹ãƒ†ãƒƒãƒ—1: æŒ‡æ•°ãƒ‡ãƒ¼ã‚¿è§£æé–‹å§‹...")
    try:
        idx = yf.download("^GSPC", period="75d", progress=False, auto_adjust=True)
        if idx.empty: return "åˆ¤å®šä¸èƒ½", 0, 0, 0
        if isinstance(idx.columns, pd.MultiIndex): idx.columns = idx.columns.get_level_values(0)
        
        c = idx['Close'].squeeze()
        v = idx['Volume'].squeeze()
        v_sma50 = v.rolling(50).mean()
        changes = c.pct_change()
        last_index_change = changes.iloc[-1]
        
        dist_days = 0
        for i in range(25, 0, -1):
            curr, prev = -i, -i-1
            if changes.iloc[curr] <= -0.002 and v.iloc[curr] > v.iloc[prev] and v.iloc[curr] > v_sma50.iloc[curr]:
                if not (c.iloc[curr+1:] >= c.iloc[curr] * 1.05).any(): dist_days += 1
        
        window_25 = c.tail(25)
        low_val = window_25.min()
        days_since_low = len(window_25) - 1 - window_25.argmin()
        
        ft_found = False
        if days_since_low >= 4:
            for i in range(int(days_since_low), 3, -1):
                if changes.iloc[-i] >= 0.015 and v.iloc[-i] > v.iloc[-i-1]:
                    ft_found = True; break

        sma50 = c.rolling(50).mean().iloc[-1]
        curr_price = c.iloc[-1]
        if ft_found and curr_price > sma50: status = "ğŸš€ ä¸Šæ˜‡ç¢ºå®š (Confirmed Uptrend)"
        elif dist_days >= 6: status = "ğŸ”´ ä¸‹è½è­¦æˆ’ (Market Under Pressure)"
        elif days_since_low > 0 and not (c.tail(int(days_since_low)+1).iloc[1:] < low_val).any() and not ft_found:
            status = "ğŸŸ¡ ãƒ©ãƒªãƒ¼è©¦è¡Œä¸­ (Rally Attempt)"
        else: status = "ğŸ“‰ ä¸‹è½ãƒˆãƒ¬ãƒ³ãƒ‰ (Downtrend)" if curr_price < sma50 else "ğŸ”„ èª¿æ•´ä¸­ (Correcting)"
                
        return status, dist_days, int(days_since_low), last_index_change
    except Exception as e:
        log(f"âŒ å¸‚å ´åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
        return "ã‚¨ãƒ©ãƒ¼åœæ­¢", 0, 0, 0

def get_full_universe():
    """SECã‹ã‚‰ä¸»è¦å–å¼•æ‰€ã®éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    log(">> ã‚¹ãƒ†ãƒƒãƒ—2: éŠ˜æŸ„ãƒªã‚¹ãƒˆå–å¾—ä¸­...")
    url = "https://www.sec.gov/files/company_tickers_exchange.json"
    headers = {'User-Agent': SEC_USER_AGENT, 'Host': 'www.sec.gov'}
    try:
        res = requests.get(url, headers=headers, timeout=25)
        json_data = res.json()
        allowed = ['Nasdaq', 'NYSE', 'NYSE American']
        tickers = [row[2].replace('-', '.') for row in json_data['data'] if row[3] in allowed]
        log(f">> âœ… {len(tickers)} éŠ˜æŸ„ã‚’ç‰¹å®šã€‚")
        return tickers
    except Exception as e:
        log(f"ã€ã‚¨ãƒ©ãƒ¼ã€‘ãƒªã‚¹ãƒˆå–å¾—å¤±æ•—: {e}"); return []

def run_screener():
    log("=== ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ V3 èµ·å‹•ï¼ˆç™ºå°„å°ã‚¹ã‚³ã‚¢æ­è¼‰ï¼‰ ===")
    mkt_status, dist_count, low_days, index_change = get_market_health_summary()
    market_summary = f"{mkt_status} (å£²ã‚ŠæŠœã‘:{dist_count}æ—¥ / å®‰å€¤ã‹ã‚‰:{low_days}æ—¥ç›®)"
    log(f"--- å¸‚å ´ç’°å¢ƒ: {market_summary} ---")

    universe = get_full_universe()
    if not universe: return

    results = []
    advances, declines = 0, 0
    total = len(universe)

    for i in range(0, total, BATCH_SIZE):
        batch = universe[i:i + BATCH_SIZE]
        try:
            log(f"    [é€²æ—] {i}/{total} åˆ†æä¸­...")
            data = yf.download(batch, period="1y", interval="1d", progress=False, auto_adjust=True, threads=True)
            if data.empty: time.sleep(120); continue

            for ticker in batch:
                try:
                    if ticker not in data['Close'].columns: continue
                    df = data.xs(ticker, axis=1, level=1).dropna()
                    if len(df) < 252: continue
                    
                    # A/Dã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
                    if df['Close'].iloc[-1] > df['Close'].iloc[-2]: advances += 1
                    else: declines += 1

                    c, h, l, v = df['Close'], df['High'], df['Low'], df['Volume']
                    curr_p = c.iloc[-1]
                    
                    # æŒ‡æ¨™ç®—å‡º
                    sma20 = c.rolling(20).mean()
                    sma50 = c.rolling(50).mean()
                    sma150 = c.rolling(150).mean()
                    sma200 = c.rolling(200).mean()
                    vol_sma50 = v.rolling(50).mean()
                    high_52w = h.rolling(252).max().iloc[-1]
                    low_52w = l.rolling(252).min().iloc[-1]

                    tags = []
                    
                    # --- 1. ãƒŸãƒãƒ«ãƒ´ã‚£ãƒ‹ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ (å³å¯†8æ¡ä»¶) ---
                    template_ok = (
                        curr_p > sma50.iloc[-1] > sma150.iloc[-1] > sma200.iloc[-1] and
                        (sma200.iloc[-20:].diff().dropna() > 0).all() and
                        curr_p >= low_52w * 1.30 and
                        curr_p >= high_52w * 0.75
                    )

                    if template_ok:
                        # --- 2. 3æ®µéšVCPåç¸®åˆ¤å®š (ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ã‚¹ãƒ‘ãƒ³: 60, 90, 120æ—¥) ---
                        def check_vcp_3steps(lookback):
                            step = lookback // 3
                            # T1, T2, T3 ã®æŒ¯å¹…ã‚’è¨ˆæ¸¬
                            d1 = (h.iloc[-lookback:-lookback+step].max() - l.iloc[-lookback:-lookback+step].min()) / h.iloc[-lookback:-lookback+step].max()
                            d2 = (h.iloc[-lookback+step:-step].max() - l.iloc[-lookback+step:-step].min()) / h.iloc[-lookback+step:-step].max()
                            d3 = (h.iloc[-step:].max() - l.iloc[-step:].min()) / h.iloc[-step:].max()
                            return (d1 > d2 > d3) and (d3 < 0.10)

                        if any([check_vcp_3steps(lb) for lb in [60, 90, 120]]):
                            tags.append("VCP_3Steps_Validated")

                        # --- 3. PowerPlay & High-Base ---
                        if (curr_p/c.iloc[-40] >= 1.70) and (curr_p/h.iloc[-40:].max() >= 0.75):
                            tags.append("PowerPlay(70%+)")
                        if (1.10 <= curr_p/c.iloc[-10] <= 1.70) and (curr_p/h.iloc[-10:].max() >= 0.90):
                            tags.append("High-Base(Strict)" if (c.iloc[-5:].pct_change() >= 0.10).any() and (v.iloc[-3:] < vol_sma50.iloc[-3:]).all() else "High-Base")

                    if tags:
                        # ç™ºå°„å°ã‚¹ã‚³ã‚¢ã®ç®—å‡º
                        lp_score = calculate_launchpad_score(df, ticker, tags, index_change)
                        
                        stock = yf.Ticker(ticker)
                        info = stock.info
                        mkt_cap = info.get('marketCap', 0)
                        if 0 < mkt_cap <= 100 * 1e9:
                            rev_g, eps_g = info.get('revenueGrowth'), info.get('earningsGrowth')
                            op_cf = info.get('operatingCashflow')
                            # HTMLãƒ¬ãƒãƒ¼ãƒˆãŒä½¿ç”¨ã™ã‚‹10EMAã®ç®—å‡º
                            ema10_val = c.ewm(span=10, adjust=False).mean().iloc[-1]
                            
                            f_label = "ã€è¶…å„ªç§€ã€‘ã‚¯ãƒªã‚¢" if (rev_g or 0) >= 0.25 and (eps_g or 0) >= 0.25 else "ã€è‰¯å¥½ã€‘ä¸€éƒ¨" if (rev_g or 0) >= 0.25 or (eps_g or 0) >= 0.25 else "ã€ä¸è¶³ã€‘ä½æˆé•·"
                            
                            results.append({
                                "éŠ˜æŸ„": ticker, "ä¾¡æ ¼": round(curr_p, 2), "ãƒ‘ã‚¿ãƒ¼ãƒ³": ", ".join(tags),
                                "æˆé•·æ€§åˆ¤å®š": f_label, "å£²ä¸Šæˆé•·(%)": round(rev_g*100, 1) if rev_g else "ä¸æ˜",
                                "å–¶æ¥­åˆ©ç›Šæˆé•·(EBITDA)%": "ä¸æ˜",
                                "ç´”åˆ©ç›Šæˆé•·(%)": round(eps_g*100, 1) if eps_g else "ä¸æ˜",
                                "å–¶æ¥­CF(M)": round(op_cf/1e6, 2) if op_cf else "ä¸æ˜",
                                "æ™‚ä¾¡ç·é¡(B)": round(mkt_cap/1e9, 2), "ç™ºå°„å°ã‚¹ã‚³ã‚¢": lp_score,
                                "10EMA": round(ema10_val, 2),
                                "20SMA": round(sma20.iloc[-1], 2),
                                "50SMA": round(sma50.iloc[-1], 2)
                            })
                            log(f"      > ã€çš„ä¸­ã€‘: {ticker} (Score: {lp_score})")
                except: continue
        except Exception as e: log(f"    [ã‚¨ãƒ©ãƒ¼] ãƒãƒƒãƒ {i}: {e}")
        time.sleep(BATCH_SLEEP_BASE + random.uniform(0, 10))

    ad_ratio = round(advances/max(1, declines), 2)
    final_mkt_summary = f"{market_summary} | A/Dæ¯”:{ad_ratio} (â†‘{advances} â†“{declines})"

    df_final = pd.DataFrame(results if results else [{"çµæœ": "çš„ä¸­ãªã—"}])
    with open(LOCAL_SAVE_PATH, 'w', encoding='utf-8-sig') as f:
        f.write(f"REPORT_METADATA,{final_mkt_summary}\n")
        df_final.to_csv(f, index=False)
    
    date_str = datetime.now().strftime('%Y%m%d')
    upload_to_drive(LOCAL_SAVE_PATH, f"minervini_final_results_{date_str}.csv")

if __name__ == "__main__":
    run_screener()
