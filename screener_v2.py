import yfinance as yf
import pandas as pd
import numpy as np
import requests
import time
import random
import sys
# --- Added for OAuth 2.0 Drive Upload ---
import os
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
# ----------------------------------------

# --- è¨­å®šã‚¨ãƒªã‚¢ï¼ˆãƒ­ã‚¸ãƒƒã‚¯ä¸å¤‰ãƒ»å¾…æ©Ÿæ™‚é–“ã‚’å®Œèµ°ç”¨ã«æœ€é©åŒ–ï¼‰ ---
SEC_USER_AGENT = 'Minervini-Bot/Git-Full-v2 (contact: gozihiro17@gmail.com)'
LOCAL_SAVE_PATH = 'minervini_final_results.csv'
BATCH_SIZE = 50
# 1ä¸‡ä»¶ï¼ˆ200å›é€šä¿¡ï¼‰ã‚’5.5æ™‚é–“ã§çµ‚ãˆã‚‹ãŸã‚ã®å¾…æ©Ÿç§’æ•°ï¼ˆç´„90ç§’ï¼‰
BATCH_SLEEP_BASE = 85
# -----------------------------------------------------

def log(msg):
    """GitHubã®ãƒ­ã‚°ç”»é¢ã«å³åº§ã«å‡ºåŠ›ã™ã‚‹ï¼ˆãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å›é¿ï¼‰"""
    print(msg, flush=True)

def upload_to_drive(file_path):
    """OAuth 2.0ã‚’ä½¿ç”¨ã—ã¦Google Driveã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    client_id = os.environ.get('CLIENT_ID')
    client_secret = os.environ.get('CLIENT_SECRET')
    refresh_token = os.environ.get('REFRESH_TOKEN')
    folder_id = os.environ.get('GDRIVE_FOLDER_ID')

    if not all([client_id, client_secret, refresh_token, folder_id]):
        log("ã€è­¦å‘Šã€‘Driveè¨­å®šç”¨ã®ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return

    try:
        creds = Credentials(
            token=None,
            refresh_token=refresh_token,
            client_id=client_id,
            client_secret=client_secret,
            token_uri="https://oauth2.googleapis.com/token"
        )
        service = build('drive', 'v3', credentials=creds)
        file_metadata = {'name': file_path, 'parents': [folder_id]}
        media = MediaFileUpload(file_path, mimetype='text/csv', resumable=True)
        service.files().create(body=file_metadata, media_body=media, fields='id').execute()
        log(f">> âœ… Google Driveã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ")
    except Exception as e:
        log(f">> âŒ Driveã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")

def get_market_health_summary():
    """
    ã€2026å®Ÿæˆ¦ä»•æ§˜ã€‘å¸‚å ´ç’°å¢ƒåˆ¤å®šï¼š
    ã‚ªãƒ‹ãƒ¼ãƒ«/ãƒŸãƒãƒ«ãƒ´ã‚£ãƒ‹æµã®å³æ ¼åŸºæº–ï¼ˆ50MAå‡ºæ¥é«˜ã€5%å¤±åŠ¹ãƒ«ãƒ¼ãƒ«ã€FTDã‚¹ãƒ†ãƒ¼ãƒˆãƒã‚·ãƒ³ï¼‰ã‚’çµ±åˆã€‚
    """
    log(">> ã‚¹ãƒ†ãƒƒãƒ—1: æŒ‡æ•°ãƒ‡ãƒ¼ã‚¿è§£æã«ã‚ˆã‚‹å¸‚å ´ç’°å¢ƒã®å³å¯†åˆ¤å®šã‚’é–‹å§‹...")
    try:
        # éå»75æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆ50MAç®—å‡ºã®ãŸã‚ï¼‰
        idx = yf.download("^GSPC", period="75d", progress=False, auto_adjust=True)
        if idx.empty: return "åˆ¤å®šä¸èƒ½", 0, 0
        
        if isinstance(idx.columns, pd.MultiIndex):
            idx.columns = idx.columns.get_level_values(0)
        
        c = idx['Close'].squeeze()
        v = idx['Volume'].squeeze()
        v_sma50 = v.rolling(50).mean()
        changes = c.pct_change()
        
        # --- 1. å£²ã‚ŠæŠœã‘æ—¥ (Distribution Days) ã®å³æ ¼ã‚«ã‚¦ãƒ³ãƒˆ ---
        dist_days = 0
        # éå»25å–å¼•æ—¥ã‚’æ¤œè¨¼
        for i in range(25, 0, -1):
            curr = -i
            prev = -i - 1
            # å³æ ¼æ¡ä»¶: -0.2%ä»¥ä¸‹ã®ä¸‹è½ ã‹ã¤ å‡ºæ¥é«˜ > å‰æ—¥ ã‹ã¤ å‡ºæ¥é«˜ > 50MA
            if changes.iloc[curr] <= -0.002 and v.iloc[curr] > v.iloc[prev] and v.iloc[curr] > v_sma50.iloc[curr]:
                dd_close = c.iloc[curr]
                # 5%å¤±åŠ¹ãƒ«ãƒ¼ãƒ«: ãã®æ—¥ä»¥é™ã«çµ‚å€¤ãŒDDå½“æ—¥ã®çµ‚å€¤ã‹ã‚‰5%ä»¥ä¸Šä¸Šæ˜‡ã—ãŸã‹
                subsequent_prices = c.iloc[curr + 1:] if curr < -1 else pd.Series()
                if not (subsequent_prices >= dd_close * 1.05).any():
                    dist_days += 1
        
        # --- 2. ãƒ©ãƒªãƒ¼ã®èµ·ç‚¹ï¼ˆç›´è¿‘æœ€å®‰å€¤ï¼‰ã®ç‰¹å®š ---
        window_25 = c.tail(25)
        low_val = window_25.min()
        days_since_low = len(window_25) - 1 - window_25.argmin()
        
        # --- 3. FTD (Follow-Through Day) ã®æ¢ç´¢ã¨æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯ ---
        ft_found = False
        rally_failed = False
        
        if days_since_low > 0:
            # å®‰å€¤æ›´æ–°ãƒã‚§ãƒƒã‚¯ (Day 1 ã®å®‰å€¤ã‚’ä¸€åº¦ã§ã‚‚ä¸‹å›ã£ãŸã‚‰å¤±æ•—)
            prices_since_low = c.tail(int(days_since_low) + 1)
            if (prices_since_low.iloc[1:] < low_val).any():
                rally_failed = True
            
            # FTDã®æ¢ç´¢ (Day 4ä»¥é™)
            if not rally_failed and days_since_low >= 4:
                for i in range(int(days_since_low), 3, -1):
                    # å³æ ¼åŸºæº–: +1.5%ä»¥ä¸Š ã‹ã¤ å‡ºæ¥é«˜ãŒå‰æ—¥ã‚’ä¸Šå›ã‚‹
                    if changes.iloc[-i] >= 0.015 and v.iloc[-i] > v.iloc[-i-1]:
                        ft_found = True
                        break

        # --- 4. æœ€çµ‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®æ±ºå®š (å„ªå…ˆé †ä½ã‚’å³å®ˆ) ---
        sma50 = c.rolling(50).mean().iloc[-1]
        curr_price = c.iloc[-1]
        
        if ft_found and curr_price > sma50:
            status = "ğŸš€ ä¸Šæ˜‡ç¢ºå®š (Confirmed Uptrend)"
        elif dist_days >= 6:
            status = "ğŸ”´ ä¸‹è½è­¦æˆ’ (Market Under Pressure)"
        elif days_since_low > 0 and not rally_failed and not ft_found:
            status = "ğŸŸ¡ ãƒ©ãƒªãƒ¼è©¦è¡Œä¸­ (Rally Attempt)"
        else:
            if curr_price < sma50:
                status = "ğŸ“‰ ä¸‹è½ãƒˆãƒ¬ãƒ³ãƒ‰ (Downtrend)"
            else:
                status = "ğŸ”„ èª¿æ•´ä¸­ (Correcting)"
                
        return status, dist_days, int(days_since_low)

    except Exception as e:
        log(f"âŒ å¸‚å ´åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
        return "ã‚¨ãƒ©ãƒ¼åœæ­¢", 0, 0
        
def get_full_universe():
    """SECã‹ã‚‰ä¸»è¦å–å¼•æ‰€ï¼ˆNasdaq, NYSE, NYSE Americanï¼‰ã®éŠ˜æŸ„ãƒªã‚¹ãƒˆã®ã¿ã‚’å–å¾—"""
    log(">> ã‚¹ãƒ†ãƒƒãƒ—2: ä¸»è¦å¸‚å ´ï¼ˆNasdaq/NYSEï¼‰ã®éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—ä¸­...")
    
    url = "https://www.sec.gov/files/company_tickers_exchange.json"
    headers = {'User-Agent': SEC_USER_AGENT, 'Host': 'www.sec.gov'}
    
    try:
        res = requests.get(url, headers=headers, timeout=25)
        json_data = res.json()
        
        allowed_exchanges = ['Nasdaq', 'NYSE', 'NYSE American']
        
        tickers = [
            row[2].replace('-', '.') # index 2 ãŒ ticker
            for row in json_data['data'] 
            if row[3] in allowed_exchanges # index 3 ãŒ exchange
        ]
        
        log(f">> âœ… ä¸»è¦å¸‚å ´ã‹ã‚‰ {len(tickers)} éŠ˜æŸ„ã‚’ç‰¹å®šï¼ˆOTCç­‰ã‚’é™¤å¤–å®Œäº†ï¼‰ã€‚")
        return tickers
    except Exception as e:
        log(f"ã€ã‚¨ãƒ©ãƒ¼ã€‘ãƒªã‚¹ãƒˆå–å¾—å¤±æ•—: {e}")
        return []

def run_screener():
    log("=== ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼èµ·å‹•ï¼ˆå®Œèµ°å„ªå…ˆãƒ¢ãƒ¼ãƒ‰ï¼‰ ===")
    
    mkt_status, dist_count, low_days = get_market_health_summary()
    market_summary = f"{mkt_status} (å£²ã‚ŠæŠœã‘:{dist_count}æ—¥ / å®‰å€¤ã‹ã‚‰:{low_days}æ—¥ç›®)"
    log(f"--- å¸‚å ´ç’°å¢ƒ: {market_summary} ---")

    universe = get_full_universe()
    if not universe: return

    results = []
    advances, declines = 0, 0 # A/Dç”¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    total = len(universe)
    log(f">> ã‚¹ãƒ†ãƒƒãƒ—3: å…¨ {total} éŠ˜æŸ„ã®ã‚¹ã‚­ãƒ£ãƒ³ã‚’é–‹å§‹ã€‚")
    log(f"    1ãƒãƒƒãƒï¼ˆ{BATCH_SIZE}éŠ˜æŸ„ï¼‰ã”ã¨ã«ç´„90ç§’å¾…æ©Ÿã—ã€5.5æ™‚é–“ã‹ã‘ã¦æ…é‡ã«é€²ã¿ã¾ã™ã€‚")

    for i in range(0, total, BATCH_SIZE):
        batch = universe[i:i + BATCH_SIZE]
        try:
            log(f"    [é€²æ—] {i}/{total} åˆ†æä¸­... (ç¾åœ¨ã¾ã§ã®çš„ä¸­: {len(results)}ä»¶)")
            
            data = yf.download(batch, period="1y", interval="1d", progress=False, 
                               auto_adjust=True, threads=True, timeout=60)
            
            if data.empty:
                log(f"    [è­¦å‘Š] ãƒãƒƒãƒ {i} ã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚åˆ¶é™å›é¿ã®ãŸã‚120ç§’å¾…æ©Ÿã—ã¾ã™ã€‚")
                time.sleep(120)
                continue

            for ticker in batch:
                try:
                    if ticker not in data['Close'].columns: continue
                    df = data.xs(ticker, axis=1, level=1).dropna()
                    
                    if len(df) >= 2:
                        if df['Close'].iloc[-1] > df['Close'].iloc[-2]: advances += 1
                        else: declines += 1

                    if len(df) < 200: continue
                    
                    c, h, l, v = df['Close'], df['High'], df['Low'], df['Volume']
                    sma20, sma50, sma200 = c.rolling(20).mean(), c.rolling(50).mean(), c.rolling(200).mean()
                    ema10, vol_sma50 = c.ewm(span=10, adjust=False).mean(), v.rolling(50).mean()

                    tags = []
                    # A. VCP_Original
                    is_stage2 = (c.iloc[-1] > sma20.iloc[-1] > sma50.iloc[-1] > sma200.iloc[-1])
                    sma200_rising = (sma200.iloc[-20:].diff().dropna() > 0).all()
                    vol_dry_up = (v.iloc[-3:] < vol_sma50.iloc[-3:]).all()
                    bbw = (c.rolling(20).std() * 4) / sma20
                    bbw_min = bbw.iloc[-1] == bbw.iloc[-20:].min()
                    if is_stage2 and sma200_rising and vol_dry_up and bbw_min:
                        tags.append("VCP_Original")

                    # B. ãƒ‘ãƒ¯ãƒ¼ãƒ—ãƒ¬ã‚¤ / ãƒã‚¤ãƒ»ãƒ™ãƒ¼ã‚¹
                    if (c.iloc[-1] > sma20.iloc[-1] > sma50.iloc[-1]):
                        if (c.iloc[-1]/c.iloc[-40] >= 1.70 if len(c)>=40 else False) and (c.iloc[-1]/h.iloc[-40:].max() >= 0.75):
                            tags.append("PowerPlay(70%+)")
                        
                        is_high_base = (1.10 <= c.iloc[-1]/c.iloc[-10] <= 1.70 if len(c)>=10 else False) and (c.iloc[-1]/h.iloc[-10:].max() >= 0.90)
                        if is_high_base:
                            recent_explosion = (c.iloc[-5:].pct_change() >= 0.10).any()
                            if recent_explosion and vol_dry_up:
                                tags.append("High-Base(Strict)")
                            else:
                                tags.append("High-Base")

                    if tags:
                        stock = yf.Ticker(ticker)
                        info = stock.info
                        mkt_cap = info.get('marketCap', 0)
                        if 0 < mkt_cap <= 100 * 1e9:
                            rev_g, eps_g = info.get('revenueGrowth'), info.get('earningsGrowth')
                            
                            ebitda_g = info.get('ebitdaGrowth')
                            if ebitda_g is None:
                                try:
                                    qf = stock.quarterly_financials
                                    if 'EBITDA' in qf.index and qf.shape[1] >= 5:
                                        cur, prev = qf.loc['EBITDA'].iloc[0], qf.loc['EBITDA'].iloc[4]
                                        if prev and prev != 0: ebitda_g = (cur - prev) / abs(prev)
                                    elif 'Operating Income' in qf.index and qf.shape[1] >= 5:
                                        cur, prev = qf.loc['Operating Income'].iloc[0], qf.loc['Operating Income'].iloc[4]
                                        if prev and prev != 0: ebitda_g = (cur - prev) / abs(prev)
                                except: pass

                            ocf = info.get('operatingCashflow')
                            if ocf is None:
                                try:
                                    qf = stock.quarterly_financials
                                    if 'Operating Cash Flow' in qf.index:
                                        ocf = qf.loc['Operating Cash Flow'].iloc[0] * 4 # å¹´æ›ç®—è¿‘ä¼¼
                                except: pass
                            
                            if rev_g is None or eps_g is None: f_label = "ã€è¦ç¢ºèªã€‘ä¸è¶³"
                            elif rev_g >= 0.25 and eps_g >= 0.25: f_label = "ã€è¶…å„ªç§€ã€‘ã‚¯ãƒªã‚¢"
                            elif rev_g >= 0.25 or eps_g >= 0.25 or rev_g >= 0.50: f_label = "ã€è‰¯å¥½ã€‘ä¸€éƒ¨"
                            else: f_label = "ã€ä¸è¶³ã€‘ä½æˆé•·"

                            results.append({
                                "éŠ˜æŸ„": ticker, "ä¾¡æ ¼": round(c.iloc[-1], 2), "ãƒ‘ã‚¿ãƒ¼ãƒ³": ", ".join(tags),
                                "æˆé•·æ€§åˆ¤å®š": f_label, 
                                "å£²ä¸Šæˆé•·(%)": round(rev_g*100, 1) if rev_g else "ä¸æ˜",
                                "å–¶æ¥­åˆ©ç›Šæˆé•·(EBITDA)%": round(ebitda_g*100, 1) if ebitda_g else "ä¸æ˜",
                                "ç´”åˆ©ç›Šæˆé•·(%)": round(eps_g*100, 1) if eps_g else "ä¸æ˜",
                                "å–¶æ¥­CF(M)": round(ocf/1e6, 2) if ocf else "ä¸æ˜",
                                "æ™‚ä¾¡ç·é¡(B)": round(mkt_cap/1e9, 2)
                            })
                            log(f"      > ã€çš„ä¸­ã€‘: {ticker}")
                except: continue
        except Exception as e:
            log(f"    [ã‚¨ãƒ©ãƒ¼] ãƒãƒƒãƒ {i}: {e}")
        
        time.sleep(BATCH_SLEEP_BASE + random.uniform(0, 10))

    # å¸‚å ´ã®åºƒãŒã‚Š (A/D) ã‚’ãƒ¬ãƒãƒ¼ãƒˆã«è¿½è¨˜
    ad_ratio = round(advances/max(1, declines), 2)
    special_msg = " ã€!ã€‘å†…éƒ¨æ”¹å–„ä¸­ï¼šå…ˆè¡ŒéŠ˜æŸ„ã‚’ãƒã‚§ãƒƒã‚¯ã›ã‚ˆ" if ad_ratio >= 1.5 and mkt_status in ["ğŸŸ¡ ãƒ©ãƒªãƒ¼è©¦è¡Œä¸­ (Rally Attempt)", "ğŸ”´ ä¸‹è½è­¦æˆ’ (Market Under Pressure)"] else ""
    
    # ã“ã“ã‚’ mkt_status ã§ã¯ãªã market_summary ã«æˆ»ã—ã¾ã™
    final_mkt_summary = f"{market_summary} | A/Dæ¯”:{ad_ratio} (â†‘{advances} â†“{declines}){special_msg}"

    df_final = pd.DataFrame(results if results else [{"çµæœ": "çš„ä¸­ãªã—"}])
    with open(LOCAL_SAVE_PATH, 'w', encoding='utf-8-sig') as f:
        f.write(f"REPORT_METADATA,{final_mkt_summary}\n")
        df_final.to_csv(f, index=False)
    
    log(f"=== å…¨å·¥ç¨‹å®Œäº†ã€‚æœ€çµ‚çš„ä¸­æ•°: {len(results)} ===")
    upload_to_drive(LOCAL_SAVE_PATH)

if __name__ == "__main__":
    run_screener()
