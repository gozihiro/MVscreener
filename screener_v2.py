import yfinance as yf
import pandas as pd
import numpy as np
import requests
import time
import random
import sys
# --- Added for OAuth 2.0 Drive Upload ---
import os
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
# ----------------------------------------

# --- è¨­å®šã‚¨ãƒªã‚¢ï¼ˆãƒ­ã‚¸ãƒƒã‚¯ä¸å¤‰ãƒ»å¾…æ©Ÿæ™‚é–“ã‚’å®Œèµ°ç”¨ã«æœ€é©åŒ–ï¼‰ ---
SEC_USER_AGENT = 'Minervini-Bot/Git-Full-v2 (contact: gozihiro17@gmail.com)'
LOCAL_SAVE_PATH = 'minervini_final_results.csv'
BATCH_SIZE = 50
# 1ä¸‡ä»¶ï¼ˆ200å›é€šä¿¡ï¼‰ã‚’5.5æ™‚é–“ã§çµ‚ãˆã‚‹ãŸã‚ã®å¾…æ©Ÿç§’æ•°ï¼ˆç´„90ç§’ï¼‰
BATCH_SLEEP_BASE = 85
# -----------------------------------------------------

def log(msg):
    """GitHubã®ãƒ­ã‚°ç”»é¢ã«å³åº§ã«å‡ºåŠ›ã™ã‚‹ï¼ˆãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å›é¿ï¼‰"""
    print(msg, flush=True)

def upload_to_drive(file_path):
    """OAuth 2.0ã‚’ä½¿ç”¨ã—ã¦Google Driveã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    client_id = os.environ.get('CLIENT_ID')
    client_secret = os.environ.get('CLIENT_SECRET')
    refresh_token = os.environ.get('REFRESH_TOKEN')
    folder_id = os.environ.get('GDRIVE_FOLDER_ID')

    if not all([client_id, client_secret, refresh_token, folder_id]):
        log("ã€è­¦å‘Šã€‘Driveè¨­å®šç”¨ã®ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return

    try:
        creds = Credentials(
            token=None,
            refresh_token=refresh_token,
            client_id=client_id,
            client_secret=client_secret,
            token_uri="https://oauth2.googleapis.com/token"
        )
        service = build('drive', 'v3', credentials=creds)
        file_metadata = {'name': file_path, 'parents': [folder_id]}
        media = MediaFileUpload(file_path, mimetype='text/csv', resumable=True)
        service.files().create(body=file_metadata, media_body=media, fields='id').execute()
        log(f">> âœ… Google Driveã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ")
    except Exception as e:
        log(f">> âŒ Driveã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")

def get_market_health_summary():
    """
    ã€2026å®Ÿæˆ¦ä»•æ§˜ã€‘å¸‚å ´ç’°å¢ƒåˆ¤å®šï¼š
    FTDç„¡åŠ¹åŒ–ãƒ­ã‚¸ãƒƒã‚¯ã€å£²ã‚ŠæŠœã‘æ—¥å„ªå…ˆåˆ¤å®šã€SMA50ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’çµ±åˆã€‚
    """
    log(">> ã‚¹ãƒ†ãƒƒãƒ—1: æŒ‡æ•°ãƒ‡ãƒ¼ã‚¿è§£æã«ã‚ˆã‚‹å¸‚å ´ç’°å¢ƒã®å³å¯†åˆ¤å®šã‚’é–‹å§‹...")
    try:
        # éå»60æ—¥åˆ†ã®S&P500ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        idx = yf.download("^GSPC", period="60d", progress=False, auto_adjust=True)
        if idx.empty: return "åˆ¤å®šä¸èƒ½", 0, 0
        
        # yfinanceã®ãƒãƒ«ãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾ç­–
        if isinstance(idx.columns, pd.MultiIndex):
            idx.columns = idx.columns.get_level_values(0)
        
        c = idx['Close'].squeeze()
        v = idx['Volume'].squeeze()
        changes = c.pct_change()
        
        # --- 1. å£²ã‚ŠæŠœã‘æ—¥ (Distribution Days) ã®ã‚«ã‚¦ãƒ³ãƒˆ ---
        # éå»25å–å¼•æ—¥ã«ãŠã„ã¦ã€Œä¾¡æ ¼ä¸‹è½ ã‹ã¤ å‡ºæ¥é«˜å¢—ã€ã®æ—¥ã‚’æ•°ãˆã‚‹
        dist_days = sum(1 for i in range(1, 26) if c.iloc[-i] < c.iloc[-i-1] and v.iloc[-i] > v.iloc[-i-1])
        
        # --- 2. ãƒ©ãƒªãƒ¼ã®èµ·ç‚¹ï¼ˆç›´è¿‘æœ€å®‰å€¤ï¼‰ã®ç‰¹å®š ---
        # éå»20æ—¥ã®ä¸­ã§ã®æœ€å®‰å€¤ã‚’ã€Œãƒ©ãƒªãƒ¼é–‹å§‹ç‚¹ã€ã®å€™è£œã¨ã™ã‚‹
        window_20 = c.tail(20)
        low_val = window_20.min()
        # æœ€å®‰å€¤ãŒä½•æ—¥å‰ã‹ã‚’ç‰¹å®š
        days_since_low = len(window_20) - 1 - window_20.argmin()
        
        # --- 3. FTD (Follow-Through Day) ã®æ¢ç´¢ã¨æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯ ---
        ftd_found = False
        rally_failed = False
        
        if days_since_low > 0:
            # ã€é‡è¦ã€‘å®‰å€¤æ›´æ–°ãƒã‚§ãƒƒã‚¯
            # ãƒ©ãƒªãƒ¼é–‹å§‹å¾Œã«ã€ãã®å®‰å€¤ã‚’ä¸€åº¦ã§ã‚‚ä¸‹å›ã£ã¦ã„ãŸã‚‰ã€Œãƒ©ãƒªãƒ¼å¤±æ•—ã€
            prices_since_low = c.tail(int(days_since_low) + 1)
            if (prices_since_low.iloc[1:] < low_val).any():
                rally_failed = True
            
            # ãƒ©ãƒªãƒ¼ãŒå¤±æ•—ã—ã¦ã„ãªã‘ã‚Œã°ã€4æ—¥ç›®ä»¥é™ã«FTDãŒã‚ã£ãŸã‹æ¢ã™
            if not rally_failed and days_since_low >= 4:
                # å®‰å€¤ã‹ã‚‰4æ—¥ç›®ã€œç¾åœ¨ã¾ã§ã®æœŸé–“ã‚’ã‚¹ã‚­ãƒ£ãƒ³
                for i in range(int(days_since_low), 3, -1):
                    # æ¡ä»¶: å‰æ—¥æ¯”+1.7%ä»¥ä¸Š ã‹ã¤ å‡ºæ¥é«˜ãŒå‰æ—¥ã‚’ä¸Šå›ã‚‹
                    if changes.iloc[-i] >= 0.017 and v.iloc[-i] > v.iloc[-i-1]:
                        ftd_found = True
                        break

        # --- 4. æœ€çµ‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®æ±ºå®š (å„ªå…ˆé †ä½ã‚’å³å®ˆ) ---
        sma50 = c.rolling(50).mean().iloc[-1]
        curr_price = c.iloc[-1]
        
        # A. æœ€å„ªå…ˆï¼šä¸Šæ˜‡ç¢ºå®š (FTDã‚ã‚Š ä¸”ã¤ SMA50ã®ä¸Š)
        if ftd_found and curr_price > sma50:
            status = "ğŸš€ ä¸Šæ˜‡ç¢ºå®š (Confirmed Uptrend)"
            
        # B. æ¬¡ç‚¹ï¼šä¸‹è½è­¦æˆ’ (å£²ã‚ŠæŠœã‘æ—¥ãŒ6æ—¥ä»¥ä¸Š)
        # â€»ãŸã¨ãˆFTDãŒå‡ºã¦ã„ã¦ã‚‚ã€å£²ã‚ŠæŠœã‘æ—¥ãŒå¤šã‘ã‚Œã°ã“ã¡ã‚‰ã‚’å„ªå…ˆã—ã¦è­¦å‘Šã™ã‚‹
        elif dist_days >= 6:
            status = "ğŸ”´ ä¸‹è½è­¦æˆ’ (Market Under Pressure)"
            
        # C. ãƒ©ãƒªãƒ¼ç¶™ç¶šä¸­ (å®‰å€¤ã‚’å‰²ã£ã¦ãŠã‚‰ãšã€FTDå¾…ã¡ã®çŠ¶æ…‹)
        elif days_since_low > 0 and not rally_failed and not ftd_found:
            status = "ğŸŸ¡ ãƒ©ãƒªãƒ¼è©¦è¡Œä¸­ (Rally Attempt)"
            
        # D. ãƒ©ãƒªãƒ¼å¤±æ•—ã¾ãŸã¯å®‰å€¤æ›´æ–°ä¸­
        else:
            if curr_price < sma50:
                status = "ğŸ“‰ ä¸‹è½ãƒˆãƒ¬ãƒ³ãƒ‰ (Downtrend)"
            else:
                status = "ğŸ”„ èª¿æ•´ä¸­ (Correcting)"
                
        return status, dist_days, int(days_since_low)

    except Exception as e:
        log(f"âŒ å¸‚å ´åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
        return "ã‚¨ãƒ©ãƒ¼åœæ­¢", 0, 0
        
def get_full_universe():
    """SECã‹ã‚‰ä¸»è¦å–å¼•æ‰€ï¼ˆNasdaq, NYSE, NYSE Americanï¼‰ã®éŠ˜æŸ„ãƒªã‚¹ãƒˆã®ã¿ã‚’å–å¾—"""
    log(">> ã‚¹ãƒ†ãƒƒãƒ—2: ä¸»è¦å¸‚å ´ï¼ˆNasdaq/NYSEï¼‰ã®éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—ä¸­...")
    
    # å–å¼•æ‰€æƒ…å ±ãŒå«ã¾ã‚Œã‚‹æ‹¡å¼µç‰ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™
    url = "https://www.sec.gov/files/company_tickers_exchange.json"
    headers = {'User-Agent': SEC_USER_AGENT, 'Host': 'www.sec.gov'}
    
    try:
        res = requests.get(url, headers=headers, timeout=25)
        json_data = res.json()
        
        # ç›£è¦–å¯¾è±¡ã‚’ä¸»è¦ãªå–å¼•æ‰€ã«é™å®šï¼ˆOTCã‚„BATSãªã©ã®ãƒã‚¤ãƒŠãƒ¼å¸‚å ´ã‚’é™¤å¤–ï¼‰
        allowed_exchanges = ['Nasdaq', 'NYSE', 'NYSE American']
        
        tickers = [
            row[2].replace('-', '.') # index 2 ãŒ ticker
            for row in json_data['data'] 
            if row[3] in allowed_exchanges # index 3 ãŒ exchange
        ]
        
        log(f">> âœ… ä¸»è¦å¸‚å ´ã‹ã‚‰ {len(tickers)} éŠ˜æŸ„ã‚’ç‰¹å®šï¼ˆOTCç­‰ã‚’é™¤å¤–å®Œäº†ï¼‰ã€‚")
        return tickers
    except Exception as e:
        log(f"ã€ã‚¨ãƒ©ãƒ¼ã€‘ãƒªã‚¹ãƒˆå–å¾—å¤±æ•—: {e}")
        return []

def run_screener():
    log("=== ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼èµ·å‹•ï¼ˆå®Œèµ°å„ªå…ˆãƒ¢ãƒ¼ãƒ‰ï¼‰ ===")
    
    # æŒ‡æ•°åˆ¤å®šã®å–å¾—
    mkt_status, dist_count, low_days = get_market_health_summary()
    market_summary = f"{mkt_status} (å£²ã‚ŠæŠœã‘:{dist_count}æ—¥ / å®‰å€¤ã‹ã‚‰:{low_days}æ—¥ç›®)"
    log(f"--- å¸‚å ´ç’°å¢ƒ: {market_summary} ---")

    universe = get_full_universe()
    if not universe: return

    results = []
    advances, declines = 0, 0 # A/Dç”¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    total = len(universe)
    log(f">> ã‚¹ãƒ†ãƒƒãƒ—3: å…¨ {total} éŠ˜æŸ„ã®ã‚¹ã‚­ãƒ£ãƒ³ã‚’é–‹å§‹ã€‚")
    log(f"    1ãƒãƒƒãƒï¼ˆ{BATCH_SIZE}éŠ˜æŸ„ï¼‰ã”ã¨ã«ç´„90ç§’å¾…æ©Ÿã—ã€5.5æ™‚é–“ã‹ã‘ã¦æ…é‡ã«é€²ã¿ã¾ã™ã€‚")

    for i in range(0, total, BATCH_SIZE):
        batch = universe[i:i + BATCH_SIZE]
        try:
            # 1ãƒãƒƒãƒã”ã¨ã«å¿…ãšãƒ­ã‚°ã‚’å‡ºåŠ›ã—ã¦ç”Ÿå­˜å ±å‘Š
            log(f"    [é€²æ—] {i}/{total} åˆ†æä¸­... (ç¾åœ¨ã¾ã§ã®çš„ä¸­: {len(results)}ä»¶)")
            
            # å®Œèµ°ã®ãŸã‚1å›ï¼ˆ1å¹´åˆ†ï¼‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«é›†ç´„
            data = yf.download(batch, period="1y", interval="1d", progress=False, 
                               auto_adjust=True, threads=True, timeout=60)
            
            if data.empty:
                log(f"    [è­¦å‘Š] ãƒãƒƒãƒ {i} ã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚åˆ¶é™å›é¿ã®ãŸã‚120ç§’å¾…æ©Ÿã—ã¾ã™ã€‚")
                time.sleep(120)
                continue

            for ticker in batch:
                try:
                    if ticker not in data['Close'].columns: continue
                    df = data.xs(ticker, axis=1, level=1).dropna()
                    
                    # --- A/D ã‚«ã‚¦ãƒ³ãƒˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‰ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã§å®Ÿæ–½ï¼‰ ---
                    if len(df) >= 2:
                        if df['Close'].iloc[-1] > df['Close'].iloc[-2]: advances += 1
                        else: declines += 1

                    if len(df) < 200: continue
                    
                    c, h, l, v = df['Close'], df['High'], df['Low'], df['Volume']
                    sma20, sma50, sma200 = c.rolling(20).mean(), c.rolling(50).mean(), c.rolling(200).mean()
                    ema10, vol_sma50 = c.ewm(span=10, adjust=False).mean(), v.rolling(50).mean()

                    # --- ã€ãƒ­ã‚¸ãƒƒã‚¯ç¶­æŒã€‘åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã¯ä¸€åˆ‡å¤‰ãˆã¾ã›ã‚“ ---
                    tags = []
                    # A. VCP_Original
                    is_stage2 = (c.iloc[-1] > sma20.iloc[-1] > sma50.iloc[-1] > sma200.iloc[-1])
                    sma200_rising = (sma200.iloc[-20:].diff().dropna() > 0).all()
                    vol_dry_up = (v.iloc[-3:] < vol_sma50.iloc[-3:]).all()
                    bbw = (c.rolling(20).std() * 4) / sma20
                    bbw_min = bbw.iloc[-1] == bbw.iloc[-20:].min()
                    if is_stage2 and sma200_rising and vol_dry_up and bbw_min:
                        tags.append("VCP_Original")

                    # B. ãƒ‘ãƒ¯ãƒ¼ãƒ—ãƒ¬ã‚¤ / ãƒã‚¤ãƒ»ãƒ™ãƒ¼ã‚¹
                    if (c.iloc[-1] > sma20.iloc[-1] > sma50.iloc[-1]):
                        if (c.iloc[-1]/c.iloc[-40] >= 1.70 if len(c)>=40 else False) and (c.iloc[-1]/h.iloc[-40:].max() >= 0.75):
                            tags.append("PowerPlay(70%+)")
                        
                        # High-Base(Strict) ã®æ¡ä»¶è¿½åŠ 
                        is_high_base = (1.10 <= c.iloc[-1]/c.iloc[-10] <= 1.70 if len(c)>=10 else False) and (c.iloc[-1]/h.iloc[-10:].max() >= 0.90)
                        if is_high_base:
                            recent_explosion = (c.iloc[-5:].pct_change() >= 0.10).any()
                            if recent_explosion and vol_dry_up:
                                tags.append("High-Base(Strict)")
                            else:
                                tags.append("High-Base")

                    if tags:
                        stock = yf.Ticker(ticker)
                        info = stock.info
                        mkt_cap = info.get('marketCap', 0)
                        if 0 < mkt_cap <= 100 * 1e9:
                            rev_g, eps_g = info.get('revenueGrowth'), info.get('earningsGrowth')
                            
                            # --- EBITDAæˆé•·ç‡ã¨å–¶æ¥­CFã®å–å¾—ãƒ­ã‚¸ãƒƒã‚¯å¼·åŒ– (ã“ã“ã‚’å·®ã—æ›¿ãˆ) ---
                            ebitda_g = info.get('ebitdaGrowth')
                            if ebitda_g is None:
                                try:
                                    qf = stock.quarterly_financials
                                    if 'EBITDA' in qf.index and qf.shape[1] >= 5:
                                        cur, prev = qf.loc['EBITDA'].iloc[0], qf.loc['EBITDA'].iloc[4]
                                        if prev and prev != 0: ebitda_g = (cur - prev) / abs(prev)
                                    elif 'Operating Income' in qf.index and qf.shape[1] >= 5:
                                        cur, prev = qf.loc['Operating Income'].iloc[0], qf.loc['Operating Income'].iloc[4]
                                        if prev and prev != 0: ebitda_g = (cur - prev) / abs(prev)
                                except: pass

                            ocf = info.get('operatingCashflow')
                            if ocf is None:
                                try:
                                    qf = stock.quarterly_financials
                                    if 'Operating Cash Flow' in qf.index:
                                        ocf = qf.loc['Operating Cash Flow'].iloc[0] * 4 # å¹´æ›ç®—è¿‘ä¼¼
                                except: pass
                            # --------------------------------------------------------
                            
                            if rev_g is None or eps_g is None: f_label = "ã€è¦ç¢ºèªã€‘ä¸è¶³"
                            elif rev_g >= 0.25 and eps_g >= 0.25: f_label = "ã€è¶…å„ªç§€ã€‘ã‚¯ãƒªã‚¢"
                            elif rev_g >= 0.25 or eps_g >= 0.25 or rev_g >= 0.50: f_label = "ã€è‰¯å¥½ã€‘ä¸€éƒ¨"
                            else: f_label = "ã€ä¸è¶³ã€‘ä½æˆé•·"

                            results.append({
                                "éŠ˜æŸ„": ticker, "ä¾¡æ ¼": round(c.iloc[-1], 2), "ãƒ‘ã‚¿ãƒ¼ãƒ³": ", ".join(tags),
                                "æˆé•·æ€§åˆ¤å®š": f_label, 
                                "å£²ä¸Šæˆé•·(%)": round(rev_g*100, 1) if rev_g else "ä¸æ˜",
                                "å–¶æ¥­åˆ©ç›Šæˆé•·(EBITDA)%": round(ebitda_g*100, 1) if ebitda_g else "ä¸æ˜",
                                "ç´”åˆ©ç›Šæˆé•·(%)": round(eps_g*100, 1) if eps_g else "ä¸æ˜",
                                "å–¶æ¥­CF(M)": round(ocf/1e6, 2) if ocf else "ä¸æ˜",
                                "æ™‚ä¾¡ç·é¡(B)": round(mkt_cap/1e9, 2)
                            })
                            log(f"      > ã€çš„ä¸­ã€‘: {ticker}")
                except: continue
        except Exception as e:
            log(f"    [ã‚¨ãƒ©ãƒ¼] ãƒãƒƒãƒ {i}: {e}")
        
        # æ¬¡ã®ãƒãƒƒãƒã¸ã®å¾…æ©Ÿï¼ˆå¹³å‡90ç§’ï¼‰
        time.sleep(BATCH_SLEEP_BASE + random.uniform(0, 10))

    # å¸‚å ´ã®åºƒãŒã‚Š (A/D) ã‚’ãƒ¬ãƒãƒ¼ãƒˆã«è¿½è¨˜
    ad_ratio = round(advances/max(1, declines), 2)
    special_msg = " ã€!ã€‘å†…éƒ¨æ”¹å–„ä¸­ï¼šå…ˆè¡ŒéŠ˜æŸ„ã‚’ãƒã‚§ãƒƒã‚¯ã›ã‚ˆ" if ad_ratio >= 1.5 and mkt_status in ["ğŸŸ¡ ãƒ©ãƒªãƒ¼è©¦è¡Œä¸­ (Rally Attempt)", "ğŸ”´ ä¸‹è½è­¦æˆ’ (Market Under Pressure)"] else ""
    final_mkt_summary = f"{market_summary} | A/Dæ¯”:{ad_ratio} (â†‘{advances} â†“{declines}){special_msg}"

    # æœ€çµ‚ä¿å­˜ï¼ˆ1è¡Œç›®ã«å¸‚å ´ç’°å¢ƒè©•ä¾¡ã‚’è¨˜éŒ²ï¼‰
    df_final = pd.DataFrame(results if results else [{"çµæœ": "çš„ä¸­ãªã—"}])
    with open(LOCAL_SAVE_PATH, 'w', encoding='utf-8-sig') as f:
        f.write(f"REPORT_METADATA,{final_mkt_summary}\n")
        df_final.to_csv(f, index=False)
    
    log(f"=== å…¨å·¥ç¨‹å®Œäº†ã€‚æœ€çµ‚çš„ä¸­æ•°: {len(results)} ===")
    
    # --- OAuth 2.0 ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‘¼ã³å‡ºã— ---
    upload_to_drive(LOCAL_SAVE_PATH)

if __name__ == "__main__":
    run_screener()
