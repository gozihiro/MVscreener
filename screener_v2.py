import yfinance as yf
import pandas as pd
import numpy as np
import requests
import time
import random
import sys
# --- Added for OAuth 2.0 Drive Upload ---
import os
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
# ----------------------------------------

# --- è¨­å®šã‚¨ãƒªã‚¢ï¼ˆãƒ­ã‚¸ãƒƒã‚¯ä¸å¤‰ãƒ»å¾…æ©Ÿæ™‚é–“ã‚’å®Œèµ°ç”¨ã«æœ€é©åŒ–ï¼‰ ---
SEC_USER_AGENT = 'Minervini-Bot/Git-Full-v2 (contact: gozihiro17@gmail.com)'
LOCAL_SAVE_PATH = 'minervini_final_results.csv'
BATCH_SIZE = 50      
# 1ä¸‡ä»¶ï¼ˆ200å›é€šä¿¡ï¼‰ã‚’5.5æ™‚é–“ã§çµ‚ãˆã‚‹ãŸã‚ã®å¾…æ©Ÿç§’æ•°ï¼ˆç´„90ç§’ï¼‰
BATCH_SLEEP_BASE = 85 
# -----------------------------------------------------

def log(msg):
    """GitHubã®ãƒ­ã‚°ç”»é¢ã«å³åº§ã«å‡ºåŠ›ã™ã‚‹ï¼ˆãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å›é¿ï¼‰"""
    print(msg, flush=True)

def upload_to_drive(file_path):
    """OAuth 2.0ã‚’ä½¿ç”¨ã—ã¦Google Driveã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    client_id = os.environ.get('CLIENT_ID')
    client_secret = os.environ.get('CLIENT_SECRET')
    refresh_token = os.environ.get('REFRESH_TOKEN')
    folder_id = os.environ.get('GDRIVE_FOLDER_ID')

    if not all([client_id, client_secret, refresh_token, folder_id]):
        log("ã€è­¦å‘Šã€‘Driveè¨­å®šç”¨ã®ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return

    try:
        creds = Credentials(
            token=None,
            refresh_token=refresh_token,
            client_id=client_id,
            client_secret=client_secret,
            token_uri="https://oauth2.googleapis.com/token"
        )
        service = build('drive', 'v3', credentials=creds)
        file_metadata = {'name': file_path, 'parents': [folder_id]}
        media = MediaFileUpload(file_path, mimetype='text/csv', resumable=True)
        service.files().create(body=file_metadata, media_body=media, fields='id').execute()
        log(f">> âœ… Google Driveã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ")
    except Exception as e:
        log(f">> âŒ Driveã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")

def get_market_health_summary():
    """ã€å¼·åŒ–ç‰ˆã€‘å¸‚å ´ç’°å¢ƒåˆ¤å®šï¼šFTDåˆ¤å®šã¨å£²ã‚ŠæŠœã‘æ—¥ã‚«ã‚¦ãƒ³ãƒˆã®çµ±åˆ"""
    log(">> ã‚¹ãƒ†ãƒƒãƒ—1: å¸‚å ´ç’°å¢ƒã®åˆ¤å®šã‚’é–‹å§‹...")
    try:
        idx = yf.download("^GSPC", period="60d", progress=False, auto_adjust=True)
        if idx.empty: return "åˆ¤å®šä¸èƒ½", 0, 0
        if isinstance(idx.columns, pd.MultiIndex): idx.columns = idx.columns.get_level_values(0)
        
        c, v = idx['Close'].squeeze(), idx['Volume'].squeeze()
        changes = c.pct_change()
        
        # 1. å£²ã‚ŠæŠœã‘æ—¥ (Distribution Days) - éå»25æ—¥
        dist_days = sum(1 for i in range(1, 26) if c.iloc[-i] < c.iloc[-i-1] and v.iloc[-i] > v.iloc[-i-1])
        
        # 2. ç›´è¿‘æœ€å®‰å€¤ã®ç‰¹å®š (20æ—¥çª“)
        recent_low_idx = c.rolling(window=20).apply(lambda x: x.argmin()).iloc[-1]
        days_since_low = len(c) - 1 - (len(c) - 20 + recent_low_idx)
        
        # 3. FTD (Follow-Through Day) åˆ¤å®š
        ftd_found = False
        if days_since_low >= 4:
            for i in range(int(days_since_low), 3, -1):
                if changes.iloc[-i] >= 0.017 and v.iloc[-i] > v.iloc[-i-1]:
                    ftd_found = True
                    break
        
        # 4. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ±ºå®š
        sma50 = c.rolling(50).mean().iloc[-1]
        if ftd_found and c.iloc[-1] > sma50:
            status = "ğŸš€ ä¸Šæ˜‡ç¢ºå®š (Confirmed Uptrend)"
        elif days_since_low > 0 and not ftd_found:
            status = "ğŸŸ¡ ãƒ©ãƒªãƒ¼è©¦è¡Œä¸­ (Rally Attempt)"
        elif dist_days >= 6:
            status = "ğŸ”´ ä¸‹è½è­¦æˆ’ (Market Under Pressure)"
        else:
            status = "è­¦æˆ’" if c.iloc[-1] < sma50 else "å¼·æ°—"
            
        return status, dist_days, int(days_since_low)
    except Exception as e:
        log(f"FTDåˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
        return "ã‚¨ãƒ©ãƒ¼", 0, 0

def get_full_universe():
    """SECã‹ã‚‰å…¨éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    log(">> ã‚¹ãƒ†ãƒƒãƒ—2: éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—ä¸­...")
    url = "https://www.sec.gov/files/company_tickers.json"
    headers = {'User-Agent': SEC_USER_AGENT, 'Host': 'www.sec.gov'}
    try:
        res = requests.get(url, headers=headers, timeout=25)
        return [item['ticker'].replace('-', '.') for item in res.json().values()]
    except Exception as e:
        log(f"ã€ã‚¨ãƒ©ãƒ¼ã€‘ãƒªã‚¹ãƒˆå–å¾—å¤±æ•—: {e}")
        return []

def run_screener():
    log("=== ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼èµ·å‹•ï¼ˆå®Œèµ°å„ªå…ˆãƒ¢ãƒ¼ãƒ‰ï¼‰ ===")
    
    # æŒ‡æ•°åˆ¤å®šã®å–å¾—
    mkt_status, dist_count, low_days = get_market_health_summary()
    market_summary = f"{mkt_status} (å£²ã‚ŠæŠœã‘:{dist_count}æ—¥ / å®‰å€¤ã‹ã‚‰:{low_days}æ—¥ç›®)"
    log(f"--- å¸‚å ´ç’°å¢ƒ: {market_summary} ---")

    universe = get_full_universe()
    if not universe: return

    results = []
    advances, declines = 0, 0 # A/Dç”¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    total = len(universe)
    log(f">> ã‚¹ãƒ†ãƒƒãƒ—3: å…¨ {total} éŠ˜æŸ„ã®ã‚¹ã‚­ãƒ£ãƒ³ã‚’é–‹å§‹ã€‚")
    log(f"    1ãƒãƒƒãƒï¼ˆ{BATCH_SIZE}éŠ˜æŸ„ï¼‰ã”ã¨ã«ç´„90ç§’å¾…æ©Ÿã—ã€5.5æ™‚é–“ã‹ã‘ã¦æ…é‡ã«é€²ã¿ã¾ã™ã€‚")

    for i in range(0, total, BATCH_SIZE):
        batch = universe[i:i + BATCH_SIZE]
        try:
            # 1ãƒãƒƒãƒã”ã¨ã«å¿…ãšãƒ­ã‚°ã‚’å‡ºåŠ›ã—ã¦ç”Ÿå­˜å ±å‘Š
            log(f"    [é€²æ—] {i}/{total} åˆ†æä¸­... (ç¾åœ¨ã¾ã§ã®çš„ä¸­: {len(results)}ä»¶)")
            
            # å®Œèµ°ã®ãŸã‚1å›ï¼ˆ1å¹´åˆ†ï¼‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«é›†ç´„
            data = yf.download(batch, period="1y", interval="1d", progress=False, 
                               auto_adjust=True, threads=True, timeout=60)
            
            if data.empty:
                log(f"    [è­¦å‘Š] ãƒãƒƒãƒ {i} ã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚åˆ¶é™å›é¿ã®ãŸã‚120ç§’å¾…æ©Ÿã—ã¾ã™ã€‚")
                time.sleep(120)
                continue

            for ticker in batch:
                try:
                    if ticker not in data['Close'].columns: continue
                    df = data.xs(ticker, axis=1, level=1).dropna()
                    
                    # --- A/D ã‚«ã‚¦ãƒ³ãƒˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‰ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã§å®Ÿæ–½ï¼‰ ---
                    if len(df) >= 2:
                        if df['Close'].iloc[-1] > df['Close'].iloc[-2]: advances += 1
                        else: declines += 1

                    if len(df) < 200: continue
                    
                    c, h, l, v = df['Close'], df['High'], df['Low'], df['Volume']
                    sma20, sma50, sma200 = c.rolling(20).mean(), c.rolling(50).mean(), c.rolling(200).mean()
                    ema10, vol_sma50 = c.ewm(span=10, adjust=False).mean(), v.rolling(50).mean()

                    # --- ã€ãƒ­ã‚¸ãƒƒã‚¯ç¶­æŒã€‘åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã¯ä¸€åˆ‡å¤‰ãˆã¾ã›ã‚“ ---
                    tags = []
                    # A. VCP_Original
                    is_stage2 = (c.iloc[-1] > sma20.iloc[-1] > sma50.iloc[-1] > sma200.iloc[-1])
                    sma200_rising = (sma200.iloc[-20:].diff().dropna() > 0).all()
                    vol_dry_up = (v.iloc[-3:] < vol_sma50.iloc[-3:]).all()
                    bbw = (c.rolling(20).std() * 4) / sma20
                    bbw_min = bbw.iloc[-1] == bbw.iloc[-20:].min()
                    if is_stage2 and sma200_rising and vol_dry_up and bbw_min:
                        tags.append("VCP_Original")

                    # B. ãƒ‘ãƒ¯ãƒ¼ãƒ—ãƒ¬ã‚¤ / ãƒã‚¤ãƒ»ãƒ™ãƒ¼ã‚¹
                    if (c.iloc[-1] > sma20.iloc[-1] > sma50.iloc[-1]):
                        if (c.iloc[-1]/c.iloc[-40] >= 1.70 if len(c)>=40 else False) and (c.iloc[-1]/h.iloc[-40:].max() >= 0.75):
                            tags.append("PowerPlay(70%+)")
                        
                        # High-Base(Strict) ã®æ¡ä»¶è¿½åŠ 
                        is_high_base = (1.10 <= c.iloc[-1]/c.iloc[-10] <= 1.70 if len(c)>=10 else False) and (c.iloc[-1]/h.iloc[-10:].max() >= 0.90)
                        if is_high_base:
                            recent_explosion = (c.iloc[-5:].pct_change() >= 0.10).any()
                            if recent_explosion and vol_dry_up:
                                tags.append("High-Base(Strict)")
                            else:
                                tags.append("High-Base")

                    if tags:
                        stock = yf.Ticker(ticker)
                        info = stock.info
                        mkt_cap = info.get('marketCap', 0)
                        if 0 < mkt_cap <= 100 * 1e9:
                            rev_g, eps_g = info.get('revenueGrowth'), info.get('earningsGrowth')
                            # å–¶æ¥­åˆ©ç›Šæˆé•·ã®ä»£æ›¿(ebitdaGrowth)ã¨å–¶æ¥­CFã‚’å–å¾—
                            ebitda_g = info.get('ebitdaGrowth')
                            ocf = info.get('operatingCashflow')
                            
                            if rev_g is None or eps_g is None: f_label = "ã€è¦ç¢ºèªã€‘ä¸è¶³"
                            elif rev_g >= 0.25 and eps_g >= 0.25: f_label = "ã€è¶…å„ªç§€ã€‘ã‚¯ãƒªã‚¢"
                            elif rev_g >= 0.25 or eps_g >= 0.25 or rev_g >= 0.50: f_label = "ã€è‰¯å¥½ã€‘ä¸€éƒ¨"
                            else: f_label = "ã€ä¸è¶³ã€‘ä½æˆé•·"

                            results.append({
                                "éŠ˜æŸ„": ticker, "ä¾¡æ ¼": round(c.iloc[-1], 2), "ãƒ‘ã‚¿ãƒ¼ãƒ³": ", ".join(tags),
                                "æˆé•·æ€§åˆ¤å®š": f_label, 
                                "å£²ä¸Šæˆé•·(%)": round(rev_g*100, 1) if rev_g else "ä¸æ˜",
                                "å–¶æ¥­åˆ©ç›Šæˆé•·(EBITDA)%": round(ebitda_g*100, 1) if ebitda_g else "ä¸æ˜",
                                "ç´”åˆ©ç›Šæˆé•·(%)": round(eps_g*100, 1) if eps_g else "ä¸æ˜",
                                "å–¶æ¥­CF(M)": round(ocf/1e6, 2) if ocf else "ä¸æ˜",
                                "æ™‚ä¾¡ç·é¡(B)": round(mkt_cap/1e9, 2)
                            })
                            log(f"      > ã€çš„ä¸­ã€‘: {ticker}")
                except: continue
        except Exception as e:
            log(f"    [ã‚¨ãƒ©ãƒ¼] ãƒãƒƒãƒ {i}: {e}")
        
        # æ¬¡ã®ãƒãƒƒãƒã¸ã®å¾…æ©Ÿï¼ˆå¹³å‡90ç§’ï¼‰
        time.sleep(BATCH_SLEEP_BASE + random.uniform(0, 10))

    # å¸‚å ´ã®åºƒãŒã‚Š (A/D) ã‚’ãƒ¬ãƒãƒ¼ãƒˆã«è¿½è¨˜
    ad_ratio = round(advances/max(1, declines), 2)
    special_msg = " ã€!ã€‘å†…éƒ¨æ”¹å–„ä¸­ï¼šå…ˆè¡ŒéŠ˜æŸ„ã‚’ãƒã‚§ãƒƒã‚¯ã›ã‚ˆ" if ad_ratio >= 1.5 and mkt_status in ["ğŸŸ¡ ãƒ©ãƒªãƒ¼è©¦è¡Œä¸­ (Rally Attempt)", "ğŸ”´ ä¸‹è½è­¦æˆ’ (Market Under Pressure)"] else ""
    final_mkt_summary = f"{market_summary} | A/Dæ¯”:{ad_ratio} (â†‘{advances} â†“{declines}){special_msg}"

    # æœ€çµ‚ä¿å­˜ï¼ˆ1è¡Œç›®ã«å¸‚å ´ç’°å¢ƒè©•ä¾¡ã‚’è¨˜éŒ²ï¼‰
    df_final = pd.DataFrame(results if results else [{"çµæœ": "çš„ä¸­ãªã—"}])
    with open(LOCAL_SAVE_PATH, 'w', encoding='utf-8-sig') as f:
        f.write(f"REPORT_METADATA,{final_mkt_summary}\n")
        df_final.to_csv(f, index=False)
    
    log(f"=== å…¨å·¥ç¨‹å®Œäº†ã€‚æœ€çµ‚çš„ä¸­æ•°: {len(results)} ===")
    
    # --- OAuth 2.0 ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‘¼ã³å‡ºã— ---
    upload_to_drive(LOCAL_SAVE_PATH)

if __name__ == "__main__":
    run_screener()
