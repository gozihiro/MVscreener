import os
import sys
import pandas as pd
from datetime import datetime, timedelta, timezone
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload
import io
import re

# --- ç’°å¢ƒå¤‰æ•°ã®å–å¾— ---
def get_env(name):
    return os.environ.get(name)

CLIENT_ID = get_env('CLIENT_ID')
CLIENT_SECRET = get_env('CLIENT_SECRET')
REFRESH_TOKEN = get_env('REFRESH_TOKEN')
PARENT_FOLDER_ID = get_env('GDRIVE_FOLDER_ID')

REQUIRED_COLS = [
    'éŠ˜æŸ„', 'ä¾¡æ ¼', 'ãƒ‘ã‚¿ãƒ¼ãƒ³', 'æˆé•·æ€§åˆ¤å®š', 'å£²ä¸Šæˆé•·(%)', 
    'å–¶æ¥­åˆ©ç›Šæˆé•·(EBITDA)%', 'ç´”åˆ©ç›Šæˆé•·(%)', 'å–¶æ¥­CF(M)', 'æ™‚ä¾¡ç·é¡(B)'
]

def get_drive_service():
    creds = Credentials(token=None, refresh_token=REFRESH_TOKEN, client_id=CLIENT_ID, client_secret=CLIENT_SECRET, token_uri="https://oauth2.googleapis.com/token")
    return build('drive', 'v3', credentials=creds)

def get_or_create_summary_folder(service):
    """ç¾åœ¨ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã«Summaryãƒ•ã‚©ãƒ«ãƒ€ã‚’ç‰¹å®šã¾ãŸã¯ä½œæˆ"""
    query = f"'{PARENT_FOLDER_ID}' in parents and name = 'Summary' and mimeType = 'application/vnd.google-apps.folder' and trashed = false"
    res = service.files().list(q=query, fields="files(id)").execute()
    files = res.get('files', [])
    
    if files:
        return files[0]['id']
    else:
        file_metadata = {
            'name': 'Summary',
            'mimeType': 'application/vnd.google-apps.folder',
            'parents': [PARENT_FOLDER_ID]
        }
        folder = service.files().create(body=file_metadata, fields='id').execute()
        print(f"ðŸ“ Summaryãƒ•ã‚©ãƒ«ãƒ€ã‚’æ–°è¦ä½œæˆã—ã¾ã—ãŸã€‚")
        return folder.get('id')

def get_target_time_ranges():
    jst = timezone(timedelta(hours=9))
    now = datetime.now(jst)
    ranges = []
    for i in range(7):
        day = now - timedelta(days=i)
        if day.weekday() in [1, 2, 3, 4, 5]:
            start = day.replace(hour=0, minute=0, second=0, microsecond=0)
            end = day.replace(hour=23, minute=59, second=59, microsecond=0)
            ranges.append((start, end))
        if len(ranges) == 5: break
    return sorted(ranges)

def fetch_weekly_data():
    service = get_drive_service()
    ranges = get_target_time_ranges()
    weekly_dfs = []
    market_metadatas = []

    print("=== Phase 1: ãƒ‡ãƒ¼ã‚¿åŽé›†ã¨å¸‚å ´ç’°å¢ƒè§£æž (JST) ===")
    for start, end in ranges:
        market_date = (start - timedelta(days=1)).strftime('%m/%d')
        q = f"'{PARENT_FOLDER_ID}' in parents and name = 'minervini_final_results.csv' and createdTime >= '{start.isoformat()}' and createdTime <= '{end.isoformat()}' and trashed = false"
        res = service.files().list(q=q, fields="files(id, createdTime)", orderBy="createdTime").execute()
        files = res.get('files', [])

        if files:
            req = service.files().get_media(fileId=files[0]['id'])
            fh = io.BytesIO()
            downloader = MediaIoBaseDownload(fh, req)
            done = False
            while not done: _, done = downloader.next_chunk()
            
            fh.seek(0)
            raw_content = fh.read().decode('utf-8-sig').splitlines()
            
            # 1è¡Œç›®ã®å¸‚å ´ç’°å¢ƒãƒ‡ãƒ¼ã‚¿ã‚’è§£æž
            metadata_line = raw_content[0] if raw_content else ""
            market_metadatas.append({'Date': market_date, 'Metadata': metadata_line})
            
            # ãƒ‡ãƒ¼ã‚¿æœ¬ä½“ã‚’èª­ã¿è¾¼ã¿
            df = pd.read_csv(io.StringIO("\n".join(raw_content[1:])))
            for col in REQUIRED_COLS:
                if col not in df.columns: df[col] = "ä¸æ˜Ž"
            
            df = df[REQUIRED_COLS].copy()
            df['Date'] = market_date
            weekly_dfs.append(df)
            print(f"âœ… {market_date}: åŽé›†å®Œäº† (å¸‚å ´ãƒ‡ãƒ¼ã‚¿å«ã‚€)")
        else:
            print(f"âŒ {market_date}: æœªæ¤œå‡º")

    return weekly_dfs, market_metadatas

def analyze_detailed_trend(dfs, metadatas):
    if not dfs: return None
    
    print("=== Phase 2: å¸‚å ´ãƒ»éŠ˜æŸ„ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æž ===")
    all_raw = pd.concat(dfs, ignore_index=True)
    trend_df = all_raw.groupby('éŠ˜æŸ„').size().reset_index(name='å‡ºç¾å›žæ•°')

    # å¸‚å ´ç’°å¢ƒè¡Œï¼ˆç‰¹æ®Šè¡Œï¼‰ã®ä½œæˆ
    market_row = {'éŠ˜æŸ„': '### MARKET_ENVIRONMENT ###', 'å‡ºç¾å›žæ•°': '-'}
    
    for meta in metadatas:
        date = meta['Date']
        # å¸‚å ´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç­‰ã®æŠ½å‡ºï¼ˆ"ãƒ©ãƒªãƒ¼è©¦è¡Œä¸­"ãªã©ã‚’å–å¾—ï¼‰
        market_row[f'ä¾¡æ ¼_{date}'] = meta['Metadata']
        
        # éŠ˜æŸ„ã”ã¨ã®å„é …ç›®ã‚’çµåˆ
        daily_df = [d for d in dfs if d['Date'] == date][0].set_index('éŠ˜æŸ„').add_suffix(f'_{date}')
        trend_df = trend_df.merge(daily_df.drop(columns=[f'Date_{date}']), on='éŠ˜æŸ„', how='left')

    # å¸‚å ´ç’°å¢ƒã‚’1è¡Œç›®ã«æŒ¿å…¥
    result = pd.concat([pd.DataFrame([market_row]), trend_df], ignore_index=True)
    
    # ã‚½ãƒ¼ãƒˆï¼ˆå¸‚å ´ç’°å¢ƒè¡Œã‚’æœ€ä¸Šéƒ¨ã«å›ºå®šã—ã€ä»¥é™ã¯å‡ºç¾å›žæ•°é †ï¼‰
    latest_date = dfs[-1]['Date']
    sort_col = f'å£²ä¸Šæˆé•·(%)_{latest_date}'
    if sort_col in result.columns:
        result['_sort'] = pd.to_numeric(result[sort_col], errors='coerce').fillna(-999)
        # 1è¡Œç›®ä»¥å¤–ã‚’ã‚½ãƒ¼ãƒˆ
        top = result.iloc[:1]
        others = result.iloc[1:].sort_values(by=['å‡ºç¾å›žæ•°', '_sort'], ascending=False)
        result = pd.concat([top, others]).drop(columns=['_sort'])
    
    return result.fillna('ï¼')

def upload_result_to_drive(file_path):
    service = get_drive_service()
    summary_folder_id = get_or_create_summary_folder(service)
    
    file_name = f"weekly_detailed_trend_{datetime.now().strftime('%Y%m%d')}.csv"
    file_metadata = {'name': file_name, 'parents': [summary_folder_id]}
    media = MediaFileUpload(file_path, mimetype='text/csv')
    
    query = f"'{summary_folder_id}' in parents and name = '{file_name}' and trashed = false"
    res = service.files().list(q=query).execute()
    files = res.get('files', [])

    if files:
        service.files().update(fileId=files[0]['id'], media_body=media).execute()
        print(f"âœ… Summaryãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸ: {file_name}")
    else:
        service.files().create(body=file_metadata, media_body=media).execute()
        print(f"âœ… Summaryãƒ•ã‚©ãƒ«ãƒ€ã«æ–°è¦ä¿å­˜ã—ã¾ã—ãŸ: {file_name}")

if __name__ == "__main__":
    if not all([CLIENT_ID, CLIENT_SECRET, REFRESH_TOKEN, PARENT_FOLDER_ID]):
        print("âŒ èªè¨¼æƒ…å ±ã®ä¸è¶³ã€‚")
        sys.exit(1)

    weekly_data, metadatas = fetch_weekly_data()
    if weekly_data:
        trend_result = analyze_detailed_trend(weekly_data, metadatas)
        if trend_result is not None:
            output_file = "weekly_detailed_trend.csv"
            trend_result.to_csv(output_file, index=False, encoding='utf-8-sig')
            upload_result_to_drive(output_file)
    else:
        print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã«ã‚ˆã‚Šä¸­æ–­")
