import os
import sys
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import io
import re
from datetime import datetime
from google import genai # æœ€æ–°ã® SDK
from google.genai import types
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload

# --- ç’°å¢ƒå¤‰æ•° ---
CLIENT_ID = os.environ.get('CLIENT_ID')
CLIENT_SECRET = os.environ.get('CLIENT_SECRET')
REFRESH_TOKEN = os.environ.get('REFRESH_TOKEN')
SUMMARY_FOLDER_ID = os.environ.get('SUMMARY_FOLDER_ID')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

def get_drive_service():
    creds = Credentials(token=None, refresh_token=REFRESH_TOKEN, client_id=CLIENT_ID, client_secret=CLIENT_SECRET, token_uri="https://oauth2.googleapis.com/token")
    return build('drive', 'v3', credentials=creds)

def get_latest_non_empty(row, base_col, dates):
    """æœ€æ–°ã®æ—¥ä»˜ã‹ã‚‰é¡ã£ã¦ã€æœ‰åŠ¹ãªå€¤ã‚’è¿”ã™ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³æ¬ æé˜²æ­¢ï¼‰"""
    for d in reversed(dates):
        val = str(row.get(f"{base_col}_{d}", ""))
        if val and val not in ["ï¼", "-", "ä¸æ˜", "nan", "None"]:
            return val
    return "ä¸æ˜"

def ask_gemini_comprehensive_analysis(market_history, top_stocks, universe_stats):
    """æœ€æ–°ã® google-genai SDK ã‚’ä½¿ç”¨ã—ã¦åˆ†æã‚’è¡Œã†"""
    if not GEMINI_API_KEY: return "Gemini API Key Error"
    
    try:
        client = genai.Client(api_key=GEMINI_API_KEY)
        model_id = "gemini-2.0-flash" # 2026å¹´ç¾åœ¨ã®ä¸»åŠ›ãƒ¢ãƒ‡ãƒ«ï¼ˆGemini 3 ç›¸å½“ã®æ¨è«–èƒ½åŠ›ï¼‰

        market_text = "\n".join([f"- {m['date']}: {m['raw']}" for m in market_history])
        stocks_text = "\n".join([f"- {s['ticker']}: å®šç€{s['persistence']}æ—¥, é€±æ¬¡é¨°è½:{s['change']:+.1f}%, æˆé•·:{s['growth']}%, ãƒ‘ã‚¿ãƒ¼ãƒ³:{s['pattern']}" for s in top_stocks])

        prompt = f"""
        ã‚ãªãŸã¯ãƒŸãƒãƒ«ãƒ´ã‚£ãƒ‹ã¨ã‚¨ãƒ«ãƒ€ãƒ¼åšå£«ã®è¦–ç‚¹ã‚’æŒã¤ãƒ—ãƒ­ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
        å…¨éŠ˜æŸ„ã®çµ±è¨ˆã¨ä¸Šä½éŠ˜æŸ„ã‚’æ¯”è¼ƒã—ã€å¸‚å ´ã®ã€çœŸã®å§¿ã€ã‚’æµ®ãå½«ã‚Šã«ã—ã¦ãã ã•ã„ã€‚

        ### 1. å¸‚å ´ç’°å¢ƒ
        {market_text}

        ### 2. ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¯é›†å›£ã®çµ±è¨ˆï¼ˆå…¨æ•°èª¿æŸ»çµæœï¼‰
        {universe_stats}

        ### 3. ä¸Šä½é¸å‡ºéŠ˜æŸ„ï¼ˆãƒªãƒ¼ãƒ€ãƒ¼ç¾¤ï¼‰
        {stocks_text}

        ### åˆ†ææŒ‡ç¤º
        1. ã€æ¯é›†å›£ã¨ãƒªãƒ¼ãƒ€ãƒ¼ã®æ¯”è¼ƒã€‘: å…¨éŠ˜æŸ„ã®åˆ†å¸ƒã«å¯¾ã—ã€ä¸Šä½éŠ˜æŸ„ãŒã©ã†çªå‡ºã—ã¦ã„ã‚‹ã‹ï¼ˆRSï¼‰ã‚’æ–­å®šã—ã¦ãã ã•ã„ã€‚
        2. ã€éœ€çµ¦ã®è³ªã€‘: 3æ—¥ä»¥ä¸Šå®šç€ã—ã¦ã„ã‚‹éŠ˜æŸ„æ•°ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ„å‘³ã‚’ã€æ©Ÿé–¢æŠ•è³‡å®¶ã®å‹•ãã¨çµ¡ã‚ã¦è§£èª¬ã—ã¦ãã ã•ã„ã€‚
        3. ã€å€‹åˆ¥éŠ˜æŸ„ã®æ€¥æ‰€ã€‘: ä¸Šä½5éŠ˜æŸ„ãŒãªãœé ‚ç‚¹ã«ã„ã‚‹ã®ã‹ã€å…¨éŠ˜æŸ„ã®ä¸­ã§ã®ç«‹ã¡ä½ç½®ã‚’è¸ã¾ãˆåˆ†æã—ã¦ãã ã•ã„ã€‚
        4. ã€æ¥é€±ã®æŒ‡é‡ã€‘: Gemini 3ã®é«˜åº¦æ¨è«–ã«åŸºã¥ãã€æœˆæ›œã‹ã‚‰ã®å§¿å‹¢ã‚’å…·ä½“çš„ã«æç¤ºã—ã¦ãã ã•ã„ã€‚
        â€»æ—¥æœ¬èªã€HTMLå½¢å¼ï¼ˆ<h3>, <b>, <br>ï¼‰ã§å‡ºåŠ›ã€‚
        """
        
        response = client.models.generate_content(
            model=model_id,
            contents=prompt
        )
        return response.text.replace('```html', '').replace('```', '')
    except Exception as e:
        return f"Geminiåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"

def create_intelligence_report(df):
    date_cols = sorted([c for c in df.columns if 'ä¾¡æ ¼_' in c])
    dates = [c.split('_')[-1] for c in date_cols]
    latest_date = dates[-1]

    # --- 1. å¸‚å ´è§£æ ---
    market_row = df[df['éŠ˜æŸ„'] == '### MARKET_ENVIRONMENT ###'].iloc[0]
    market_history = [{'date': d, 'raw': str(market_row.get(f'ä¾¡æ ¼_{d}', ""))} for d in dates]

    # --- 2. éŠ˜æŸ„è§£æï¼ˆå…¨æ•°èª¿æŸ»ï¼‰ ---
    stocks = df[df['éŠ˜æŸ„'] != '### MARKET_ENVIRONMENT ###'].copy()
    analysis_list = []
    
    for _, row in stocks.iterrows():
        prices = []
        for d in dates:
            p_val = pd.to_numeric(row.get(f'ä¾¡æ ¼_{d}'), errors='coerce')
            if pd.notnull(p_val): prices.append(float(p_val))
        
        if not prices: continue

        persistence = int(pd.to_numeric(row.get('å‡ºç¾å›æ•°', 0), errors='coerce') or 0)
        weekly_change = ((prices[-1] / prices[0]) - 1) * 100 if prices[0] != 0 else 0
        latest_growth = float(pd.to_numeric(get_latest_non_empty(row, "å£²ä¸Šæˆé•·(%)", dates), errors='coerce') or 0)
        final_pattern = get_latest_non_empty(row, "ãƒ‘ã‚¿ãƒ¼ãƒ³", dates)
        
        # å®šç€æ—¥æ•°ã‚’æœ€å„ªå…ˆï¼ˆ100ç‚¹/æ—¥ï¼‰ã¨ã—ãŸå …ç‰¢ãªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        score = (persistence * 100.0) + (weekly_change * 1.0) + (latest_growth * 0.5)
        
        analysis_list.append({
            'ticker': row['éŠ˜æŸ„'], 'score': score, 'persistence': persistence,
            'change': weekly_change, 'growth': latest_growth, 'pattern': final_pattern,
            'prices': prices
        })
    
    analysis_df = pd.DataFrame(analysis_list)
    
    # --- 3. å…¨éŠ˜æŸ„ã®çµ±è¨ˆ ---
    p_dist = analysis_df['persistence'].value_counts().sort_index().to_dict()
    universe_stats = f"""
    - ç·ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é€šééŠ˜æŸ„æ•°: {len(analysis_df)}ä»¶
    - å®šç€æ—¥æ•°ã®åˆ†å¸ƒ: {p_dist}
    - å…¨ä½“ã®å¹³å‡é€±æ¬¡é¨°è½ç‡: {analysis_df['change'].mean():.2f}%
    - å…¨ä½“ã®å¹³å‡å£²ä¸Šæˆé•·ç‡: {analysis_df['growth'].mean():.1f}%
    - ä¸»è¦ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†å¸ƒ: {analysis_df['pattern'].value_counts().head(5).to_dict()}
    """

    # ä¸Šä½5éŠ˜æŸ„é¸å‡º
    top_stocks = sorted(analysis_list, key=lambda x: x['score'], reverse=True)[:5]
    
    # ã€ä¿®æ­£ã€‘é–¢æ•°åã‚’æ­£ã—ãå‘¼ã³å‡ºã—
    gemini_insight = ask_gemini_comprehensive_analysis(market_history, top_stocks, universe_stats)

    # --- 4. ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ ---
    fig2 = px.scatter(
        analysis_df, x="persistence", y="change", text="ticker",
        size=[10]*len(analysis_df), color="growth",
        labels={"persistence": "å®šç€æ—¥æ•°", "change": "é€±æ¬¡é¨°è½ç‡(%)"},
        title="ğŸ“ˆ å…¨éŠ˜æŸ„åˆ†æï¼šå®šç€æ—¥æ•° vs ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆæ¯é›†å›£ã®åˆ†å¸ƒï¼‰"
    )
    fig2.update_traces(textposition='top center')
    fig2.update_layout(height=600, template="plotly_white")

    # --- 5. HTMLæ§‹ç¯‰ ---
    report_html = f"""
    <html>
    <head><meta charset='utf-8'><style>
        body {{ font-family: sans-serif; max-width: 1100px; margin: auto; padding: 20px; background: #f8f9fa; }}
        .card {{ background: white; padding: 30px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); margin-bottom: 25px; }}
        .insight-box {{ border-left: 8px solid #8e44ad; padding: 20px; background: #f3e5f5; font-size: 1.1em; line-height: 1.8; }}
        .rank-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; }}
        .rank-card {{ border: 2px solid #3498db; border-radius: 10px; padding: 15px; text-align: center; background: #fff; }}
        .badge {{ background: #e74c3c; color: white; padding: 4px 10px; border-radius: 5px; font-weight: bold; font-size: 0.9em; }}
    </style></head>
    <body>
        <h1>ğŸ“Š é€±æ¬¡ãƒ»å…¨éŠ˜æŸ„ç¶²ç¾…çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆ (Gemini 3å¯¾å¿œ)</h1>
        <div class="card">
            <h2>ğŸ§  æ¯é›†å›£çµ±è¨ˆã«åŸºã¥ãæ·±å±¤ã‚¤ãƒ³ã‚µã‚¤ãƒˆ</h2>
            <div class="insight-box">{gemini_insight}</div>
        </div>
        <div class="card">
            <h2>ğŸ† æ³¨ç›®éŠ˜æŸ„ãƒ©ãƒ³ã‚­ãƒ³ã‚° Top 5</h2>
            <div class="rank-grid">
                {"".join([f'''
                <div class="rank-card">
                    <div class="badge">{s['persistence']}/5æ—¥ å®šç€</div>
                    <h3>{s['ticker']}</h3>
                    <p>é€±æ¬¡é¨°è½: {s['change']:+.1f}%<br>å£²ä¸Šæˆé•·: {s['growth']}%</p>
                    <small><b>ãƒ‘ã‚¿ãƒ¼ãƒ³:</b><br>{s['pattern']}</small>
                </div>
                ''' for s in top_stocks])}
            </div>
        </div>
        <div class="card">
            <h2>ğŸ“Š å¸‚å ´ã®åˆ†å¸ƒï¼šå…¨éŠ˜æŸ„ãƒ—ãƒ­ãƒƒãƒˆ</h2>
            {fig2.to_html(full_html=False, include_plotlyjs='cdn')}
        </div>
    </body></html>
    """
    return report_html

def upload_to_drive(content, filename):
    service = get_drive_service()
    fh = io.BytesIO(content.encode('utf-8'))
    media = MediaIoBaseUpload(fh, mimetype='text/html', resumable=True)
    query = f"'{SUMMARY_FOLDER_ID}' in parents and name = '{filename}' and trashed = false"
    res = service.files().list(q=query).execute()
    files = res.get('files', [])
    if files:
        service.files().update(fileId=files[0]['id'], media_body=media).execute()
    else:
        service.files().create(body={'name': filename, 'parents': [SUMMARY_FOLDER_ID]}, media_body=media).execute()

if __name__ == "__main__":
    service = get_drive_service()
    query = f"'{SUMMARY_FOLDER_ID}' in parents and name contains 'weekly_detailed_trend' and trashed = false"
    res = service.files().list(q=query, fields="files(id, name)", orderBy="createdTime desc").execute()
    if not res.get('files'): sys.exit(1)
    
    file_id = res['files'][0]['id']
    req = service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, req)
    done = False
    while not done: _, done = downloader.next_chunk()
    fh.seek(0)
    trend_df = pd.read_csv(fh, dtype=str)
    
    html_report = create_intelligence_report(trend_df)
    report_filename = res['files'][0]['name'].replace('weekly_detailed_trend', 'intelligence_v2026').replace('.csv', '.html')
    upload_to_drive(html_report, report_filename)
