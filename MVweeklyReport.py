import os
import sys
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import io
import re
from datetime import datetime
import google.generativeai as genai
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload

# --- ç’°å¢ƒå¤‰æ•° ---
CLIENT_ID = os.environ.get('CLIENT_ID')
CLIENT_SECRET = os.environ.get('CLIENT_SECRET')
REFRESH_TOKEN = os.environ.get('REFRESH_TOKEN')
SUMMARY_FOLDER_ID = os.environ.get('SUMMARY_FOLDER_ID')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

def get_drive_service():
    creds = Credentials(token=None, refresh_token=REFRESH_TOKEN, client_id=CLIENT_ID, client_secret=CLIENT_SECRET, token_uri="https://oauth2.googleapis.com/token")
    return build('drive', 'v3', credentials=creds)

def get_latest_non_empty(row, base_col, dates):
    """æœ€æ–°ã®æ—¥ä»˜ã‹ã‚‰é¡ã£ã¦ã€ç©ºã§ãªã„æœ‰åŠ¹ãªå€¤ã‚’è¿”ã™"""
    for d in reversed(dates):
        val = str(row.get(f"{base_col}_{d}", ""))
        if val and val not in ["ï¼", "-", "ä¸æ˜", "nan", "None"]:
            return val
    return "ä¸æ˜"

def ask_gemini_comprehensive_analysis(market_history, top_stocks, universe_stats):
    """Gemini 3 ã«ã€å¸‚å ´ã®å…¨æ¯é›†å›£ã€ã¨ã€ä¸Šä½éŠ˜æŸ„ã€ã®æ¯”è¼ƒåˆ†æã‚’è¡Œã‚ã›ã‚‹"""
    if not GEMINI_API_KEY: return "Gemini API Key Error"
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-3-flash-preview')

    market_text = "\n".join([f"- {m['date']}: {m['raw']}" for m in market_history])
    stocks_text = "\n".join([f"- {s['ticker']}: å®šç€{s['persistence']}æ—¥, é€±æ¬¡é¨°è½:{s['change']:+.1f}%, æˆé•·:{s['growth']}%, ãƒ‘ã‚¿ãƒ¼ãƒ³:{s['pattern']}" for s in top_stocks])

    prompt = f"""
    ã‚ãªãŸã¯ãƒŸãƒãƒ«ãƒ´ã‚£ãƒ‹ã¨ã‚¨ãƒ«ãƒ€ãƒ¼åšå£«ã®è¦–ç‚¹ã‚’æŒã¤ãƒ—ãƒ­ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    ä»Šé€±ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é€šéã—ãŸå…¨éŠ˜æŸ„ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã¨ã€ãã®ä¸­ã‹ã‚‰å³é¸ã•ã‚ŒãŸä¸Šä½éŠ˜æŸ„ã‚’æ¯”è¼ƒã—ã€å¸‚å ´ã®ã€çœŸã®å§¿ã€ã‚’æµ®ãå½«ã‚Šã«ã—ã¦ãã ã•ã„ã€‚

    ### 1. å¸‚å ´ç’°å¢ƒ
    {market_text}

    ### 2. ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¯é›†å›£ï¼ˆå…¨éŠ˜æŸ„ï¼‰ã®çµ±è¨ˆ
    {universe_stats}

    ### 3. ä¸Šä½é¸å‡ºéŠ˜æŸ„ï¼ˆãƒªãƒ¼ãƒ€ãƒ¼ç¾¤ï¼‰
    {stocks_text}

    ### åˆ†æã¨æè¨€ã®æŒ‡ç¤ºï¼ˆæ—¥æœ¬èªã€HTMLå½¢å¼ï¼‰
    1. ã€æ¯é›†å›£ã¨ãƒªãƒ¼ãƒ€ãƒ¼ã®æ¯”è¼ƒåˆ†æã€‘: å…¨éŠ˜æŸ„ã®å¹³å‡çš„ãªå®šç€ç‡ã‚„é¨°è½ç‡ã«å¯¾ã—ã€ä¸Šä½éŠ˜æŸ„ãŒã©ã®ã‚ˆã†ã«çªå‡ºã—ã¦ã„ã‚‹ã‹ã€ãã®ã€Œç›¸å¯¾çš„å¼·ã•(RS)ã€ã®ä¾¡å€¤ã‚’æ–­å®šã—ã¦ãã ã•ã„ã€‚
    2. ã€éœ€çµ¦ã®è³ªã€‘: 3æ—¥ä»¥ä¸Šå®šç€ã—ã¦ã„ã‚‹éŠ˜æŸ„æ•°ã‚„ã€å…±é€šã—ã¦ç¾ã‚Œã¦ã„ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ„å‘³ï¼ˆä¾‹: High-Baseã®å¤šç™ºãŒæ„å‘³ã™ã‚‹å¼·æ°—æ„Ÿï¼‰ã‚’è§£èª¬ã—ã¦ãã ã•ã„ã€‚
    3. ã€å€‹åˆ¥éŠ˜æŸ„ã®æ€¥æ‰€ã€‘: ä¸Šä½5éŠ˜æŸ„ãŒã€Œãªãœä»Šã€ãƒªã‚¹ãƒˆã®é ‚ç‚¹ã«ã„ã‚‹ã®ã‹ã€ã‚’ã€å…¨éŠ˜æŸ„ã®ä¸­ã§ã®ç«‹ã¡ä½ç½®ã‚’è¸ã¾ãˆã¦é‹­ãçªã„ã¦ãã ã•ã„ã€‚
    4. ã€æ¥é€±ã®æŒ‡é‡ã€‘: Gemini 3ã®é«˜åº¦ãªæ¨è«–ã«ã‚ˆã‚Šã€æœˆæ›œæ—¥ã®å¯„ã‚Šä»˜ãã‹ã‚‰å–ã‚‹ã¹ãå§¿å‹¢ã‚’å…·ä½“çš„ã«æç¤ºã—ã¦ãã ã•ã„ã€‚
    """
    try:
        response = model.generate_content(prompt)
        return response.text.replace('```html', '').replace('```', '')
    except Exception as e:
        return f"Geminiåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"

def create_intelligence_report(df):
    date_cols = sorted([c for c in df.columns if 'ä¾¡æ ¼_' in c])
    dates = [c.split('_')[-1] for c in date_cols]
    latest_date = dates[-1]

    # --- 1. å¸‚å ´è§£æ ---
    market_row = df[df['éŠ˜æŸ„'] == '### MARKET_ENVIRONMENT ###'].iloc[0]
    market_history = [{'date': d, 'raw': str(market_row.get(f'ä¾¡æ ¼_{d}', ""))} for d in dates]

    # --- 2. éŠ˜æŸ„è§£æï¼ˆå…¨æ•°èª¿æŸ»ï¼‰ ---
    stocks = df[df['éŠ˜æŸ„'] != '### MARKET_ENVIRONMENT ###'].copy()
    analysis_list = []
    
    for _, row in stocks.iterrows():
        # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨ãªæŠ½å‡º
        prices = []
        for d in dates:
            p_val = pd.to_numeric(row.get(f'ä¾¡æ ¼_{d}'), errors='coerce')
            if pd.notnull(p_val): prices.append(float(p_val))
        
        if not prices: continue

        # å®šç€æ—¥æ•°ã€é¨°è½ç‡ã€æœ€æ–°æˆé•·ç‡ã‚’ç®—å‡º
        persistence = int(pd.to_numeric(row.get('å‡ºç¾å›æ•°', 0), errors='coerce') or 0)
        weekly_change = ((prices[-1] / prices[0]) - 1) * 100 if prices[0] != 0 else 0
        
        # æˆé•·ç‡ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€Œæœ€æ–°ã®æœ‰åŠ¹ãªå€¤ã€ã‚’å–å¾—
        latest_growth = float(pd.to_numeric(get_latest_non_empty(row, "å£²ä¸Šæˆé•·(%)", dates), errors='coerce') or 0)
        final_pattern = get_latest_non_empty(row, "ãƒ‘ã‚¿ãƒ¼ãƒ³", dates)
        
        # å®šç€æ—¥æ•°ã‚’æœ€å„ªå…ˆï¼ˆ100ç‚¹/æ—¥ï¼‰ã¨ã—ãŸã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        score = (persistence * 100.0) + (weekly_change * 1.0) + (latest_growth * 0.5)
        
        analysis_list.append({
            'ticker': row['éŠ˜æŸ„'], 'score': score, 'persistence': persistence,
            'change': weekly_change, 'growth': latest_growth, 'pattern': final_pattern,
            'prices': prices
        })
    
    # çµ±è¨ˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    analysis_df = pd.DataFrame(analysis_list)
    
    # --- 3. å…¨éŠ˜æŸ„ã®çµ±è¨ˆï¼ˆGeminiã¸ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆç”¨ï¼‰ ---
    p_dist = analysis_df['persistence'].value_counts().sort_index().to_dict()
    universe_stats = f"""
    - ç·ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é€šééŠ˜æŸ„æ•°: {len(analysis_df)}ä»¶
    - å®šç€æ—¥æ•°ã®åˆ†å¸ƒ (æ—¥æ•°:ä»¶æ•°): {p_dist}
    - å…¨ä½“ã®å¹³å‡é€±æ¬¡é¨°è½ç‡: {analysis_df['change'].mean():.2f}%
    - å…¨ä½“ã®å¹³å‡å£²ä¸Šæˆé•·ç‡: {analysis_df['growth'].mean():.1f}%
    - ä¸»è¦ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†å¸ƒ: {analysis_df['pattern'].value_counts().head(5).to_dict()}
    """

    # ä¸Šä½5éŠ˜æŸ„é¸å‡º
    top_stocks = sorted(analysis_list, key=lambda x: x['score'], reverse=True)[:5]
    gemini_insight = ask_comprehensive_analysis(market_history, top_stocks, universe_stats)

    # --- 4. ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆï¼ˆå®šç€ãƒãƒˆãƒªã‚¯ã‚¹ï¼‰ ---
    fig2 = px.scatter(
        analysis_df, x="persistence", y="change", text="ticker",
        size=[10]*len(analysis_df), color="growth",
        labels={"persistence": "å®šç€æ—¥æ•°", "change": "é€±æ¬¡é¨°è½ç‡(%)"},
        title="ğŸ“ˆ å…¨éŠ˜æŸ„åˆ†æï¼šå®šç€æ—¥æ•° vs ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆæ¯é›†å›£ã®åˆ†å¸ƒï¼‰"
    )
    fig2.update_traces(textposition='top center')
    fig2.update_layout(height=600, template="plotly_white")

    # --- 5. HTMLæ§‹ç¯‰ ---
    report_html = f"""
    <html>
    <head><meta charset='utf-8'><style>
        body {{ font-family: sans-serif; max-width: 1100px; margin: auto; padding: 20px; background: #f8f9fa; }}
        .card {{ background: white; padding: 30px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); margin-bottom: 25px; }}
        .insight-box {{ border-left: 8px solid #8e44ad; padding: 20px; background: #f3e5f5; font-size: 1.1em; line-height: 1.8; }}
        .rank-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; }}
        .rank-card {{ border: 2px solid #3498db; border-radius: 10px; padding: 15px; text-align: center; background: #fff; }}
        .badge {{ background: #e74c3c; color: white; padding: 4px 10px; border-radius: 5px; font-weight: bold; font-size: 0.9em; }}
    </style></head>
    <body>
        <h1>ğŸ“Š é€±æ¬¡ãƒ»å…¨éŠ˜æŸ„ç¶²ç¾…çš„æ·±å±¤ãƒ¬ãƒãƒ¼ãƒˆ (Gemini 3)</h1>
        <div class="card">
            <h2>ğŸ§  å…¨æ¯é›†å›£ã®åˆ†æã«åŸºã¥ã Gemini ã‚¤ãƒ³ã‚µã‚¤ãƒˆ</h2>
            <div class="insight-box">{gemini_insight}</div>
        </div>
        <div class="card">
            <h2>ğŸ† æ³¨ç›®éŠ˜æŸ„ãƒ©ãƒ³ã‚­ãƒ³ã‚° Top 5</h2>
            <div class="rank-grid">
                {"".join([f'''
                <div class="rank-card">
                    <div class="badge">{s['persistence']}/5æ—¥ å®šç€</div>
                    <h3>{s['ticker']}</h3>
                    <p>é€±æ¬¡å¤‰åŒ–: {s['change']:+.1f}%<br>å£²ä¸Šæˆé•·: {s['growth']}%</p>
                    <small><b>ãƒ‘ã‚¿ãƒ¼ãƒ³:</b><br>{s['pattern']}</small>
                </div>
                ''' for s in top_stocks])}
            </div>
        </div>
        <div class="card">
            <h2>ğŸ“Š å¸‚å ´ã®åˆ†å¸ƒå¯è¦–åŒ–</h2>
            {fig2.to_html(full_html=False, include_plotlyjs='cdn')}
        </div>
    </body></html>
    """
    return report_html

# upload_to_drive, main ç­‰ã¯å‰å›ã¨åŒæ§˜ï¼ˆç•¥ï¼‰
def upload_to_drive(content, filename):
    service = get_drive_service()
    fh = io.BytesIO(content.encode('utf-8'))
    media = MediaIoBaseUpload(fh, mimetype='text/html', resumable=True)
    query = f"'{SUMMARY_FOLDER_ID}' in parents and name = '{filename}' and trashed = false"
    res = service.files().list(q=query).execute()
    files = res.get('files', [])
    if files:
        service.files().update(fileId=files[0]['id'], media_body=media).execute()
    else:
        service.files().create(body={'name': filename, 'parents': [SUMMARY_FOLDER_ID]}, media_body=media).execute()

if __name__ == "__main__":
    service = get_drive_service()
    query = f"'{SUMMARY_FOLDER_ID}' in parents and name contains 'weekly_detailed_trend' and trashed = false"
    res = service.files().list(q=query, fields="files(id, name)", orderBy="createdTime desc").execute()
    if not res.get('files'): sys.exit(1)
    
    file_id = res['files'][0]['id']
    req = service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, req)
    done = False
    while not done: _, done = downloader.next_chunk()
    fh.seek(0)
    trend_df = pd.read_csv(fh, dtype=str)
    
    html_report = create_intelligence_report(trend_df)
    report_filename = res['files'][0]['name'].replace('weekly_detailed_trend', 'intelligence_full').replace('.csv', '.html')
    upload_to_drive(html_report, report_filename)
